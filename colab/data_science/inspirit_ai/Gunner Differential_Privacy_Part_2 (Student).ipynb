{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Gunner Differential_Privacy_Part_2 (Student).ipynb","provenance":[{"file_id":"1zvS6LneiIHZdzHdr7_tjx2zqYZvmevqa","timestamp":1627830089520}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bwz0zv46a2VP"},"source":["# Introducing Differential Privacy\n","\n","Welcome to the second notebook in this module! Last time, we saw that language models display unintended **memorization** of private information that they are trained on. Worse yet, this information can be extracted using simple attacks.\n","\n","If training data comes from the web or from users, private information in training data is inevitable, so we need ways to mitigate memorization.\n","\n","![link](https://1gew6o3qn6vx9kp3s42ge0y1-wpengine.netdna-ssl.com/wp-content/uploads/prod/sites/5/2020/06/kahanpiece-768x432.jpg)\n","\n","This will be the outline for today's notebook:\n","1. Understanding the problem of trust\n","2. Creating a randomized response algorithm\n","3. Using the randomized response algorithm\n","4. Using differential privacy to create Lawbot 2.0"]},{"cell_type":"markdown","metadata":{"id":"K_usbY06OOGc"},"source":["## Important: Go to Runtime > Check runtime type is GPU as the hardware acceleration. "]},{"cell_type":"code","metadata":{"id":"C_n43XWCa2VQ"},"source":["#@title Run this cell to get started! This'll load some packages and set up some dependencies for us\n","\n","import numpy as np\n","import random\n","np.random.seed(42)\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()\n","tf.set_random_seed(42)\n","if tf.test.gpu_device_name():\n","  print(\"You're using GPU!\")\n","else:\n","  print(\"You're not using GPU. You can by going to Runtime > Change runtime type.\")\n","%load_ext tensorboard\n","import pickle\n","import tensorflow_datasets as tfds\n","from matplotlib import pyplot as plt\n","from datetime import datetime\n","import os\n","import time\n","\n","!pip install git+https://github.com/tensorflow/privacy\n","from tensorflow_privacy.privacy.analysis import privacy_ledger\n","from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n","from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n","from tensorflow_privacy.privacy.optimizers import dp_optimizer\n","\n","# import requests\n","# import zipfile\n","# import io\n","\n","# # Download class resources...\n","# r = requests.get(\"https://www.dropbox.com/s/t2hidep7xfatnat/part2_materials.zip?dl=1\")\n","# z = zipfile.ZipFile(io.BytesIO(r.content))\n","# z.extractall()\n","\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/Deep%20Dives/Advanced%20Topics%20in%20AI/Sessions%206%20-%2010%20(Projects)/Project%20-%20Differential%20Privacy/part2_materials.zip'\n","!unzip part2_materials.zip\n","\n","LEARNING_RATE = 0.001\n","SEQUENCE_LENGTH = 20\n","EMBEDDING_DIM = 50\n","LSTM_DIM = 100\n","VOCAB_LENGTH = 985\n","BATCH_SIZE = 100\n","NUM_EPOCHS = 4\n","EVAL_FREQUENCY = 1\n","SPACE_ID = 777"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8kow365Cn6c"},"source":["## The problem of trust\n","\n","### Sampling students\n","\n","Now let's pretend that you are a sociologist. As part of your research on academic cheating, you want to survey a sample of students at your local university and find out what percentage of them have violated the Honor Code.\n","\n","**Question**: What types of questions should you ask? What problems might you run into? (hint: what do you think students will say?)\n","\n","![link](https://cdn.searchenginejournal.com/wp-content/uploads/2019/07/top-5-free-survey-makers-760x400.png)"]},{"cell_type":"markdown","metadata":{"id":"TtSK0yLBKT9M"},"source":["### Confidentiality\n","\n","We can only expect accurate survey results if students feel comfortable enough to share the truth about any Honor Code violations with us. We might consider how we can make our survey **confidential**, meaning that we ensure no one but us and a student will know that student's answer.\n","\n","**Question**: What are some ways that we can ensure the confidentiality of students who take our survey?\n","\n","**Question**: How can we communicate to students that our survey is confidential?\n","\n","**Question**: Is this secure?\n","\n","[Link](https://lh3.googleusercontent.com/proxy/EcEhm-Z_lR3idNAQ2TyoC4LS3cGA1rbv8wSHyqS30RvWp_bPyBG8yz9Qeg6St1wJoCJtXoE88f6wtuiswdk9SbcwaGPOFyp1ds460lIRCX6r4mtD4DX8Z7B1BuQHpH5_bXs6PXNKm1cIzXHAZWIqOFNBRTmuOK6q_FwhkCrbR3sb)\n","\n","### But the leaking persists...\n","\n","Despite the best intentions of researchers and others, data can be stolen or even *unintentionally leaked!* In the previous notebook, we explored how the government trained a **natural language processing** (NLP) model on its government files and unintentionally leaked our private PIN number.\n","\n","Even simple calculations can unintentionally leak information about survey participants! For example, suppose that we survey all ten students in a chemistry class. We find that only two students, Alice and Bob, violated the Honor Code. To ensure confidentiality, we don't tell anyone about the individual survey results -- in fact, we delete the individual survey results once we are done. The only information we release in our paper is that 20% of students in the class cheated.\n","\n","**Question**: Is there any way that students' survey results could still be found out? If so, how could we prevent this problem?\n","\n","![link](https://2.bp.blogspot.com/_xMu1JOybE2U/S_0548zzjDI/AAAAAAAAAt8/bpu3pk-miWE/s1600/cheating.jpg)"]},{"cell_type":"markdown","metadata":{"id":"fYK0WRUlyRFV"},"source":["## Randomized response algorithms\n","\n","### Exploring the randomized response algorithm\n","\n","We've explored how hard it is to get accurate results for our survey! Our students just might not trust us since there is always the risk that their Honor Code violations will be found out. So what can we do?\n","\n","We want our survey participants to have **plausible deniability** even if other survey participants release their results, their confidential survey information is leaked, the researcher is evil, etc.\n","\n","So how can we achieve this? Well, we can achieve this by automatically running each survey response through a **randomized algorithm**, which returns a **randomized response**. Only the randomized response is sent to the survey administrator. To illustrate what we mean, take a look at the below flow chart:\n","\n","<img src=\"http://zouds.com/public/inspirit/coin_flip_flow.png\"/>\n","\n","As we can see, our randomized algorithm *doesn't always return the survey participant's answer accurately*. Let's calculate the probability that the algorithm will accurately return the survey participant's answer!\n","\n","**Note**: In this flow chart, \"Yes\" means that the Honor Code was violated and \"No\" means that the Honor Code was not violated.\n","\n","**Question**: Suppose a participant reports they have violated the Honor Code. What is the probability that our randomized algorithm will return \"Yes\"? What is the probability that our randomized algorithm will return \"No\"?\n","\n","**Question**: Suppose, alternatively, a participant reports they have *not* violated the Honor Code. What is the probability that our randomized algorithm will return \"Yes\"? What is the probability that our randomized algorithm will return \"No\"?\n","\n","**Question**: Based on your answers to the previous two questions, what is the probability that our algorithm will *accurately* report a participant's answer?\n","\n","**Question**: Does this randomized algorithm give participants plausible deniability?\n","\n","**Optional**: To learn more about randomized response, check out [this website](http://www.milefoot.com/math/stat/prob-randresponse.htm)."]},{"cell_type":"markdown","metadata":{"id":"yH6rnJklQp0A"},"source":["### Implementing the randomized response algorithm\n","\n","**Exercise**: Fill in the function below to implement the randomized response algorithm. Your algorithm should match the flow chart above. In your algorithm, `True` means \"Yes, I have violated the Honor Code\", and `False` means \"No, I have *not* violated the Honor Code\".\n","\n","**Hint**: To perform a coin flip, you should check out the `random` Python library."]},{"cell_type":"code","metadata":{"id":"Sc6Qdpdk7TzK"},"source":["\"\"\"\n","Input: actual_response -- A boolean, either True or False\n","Output: A boolean, either True or False\n","\"\"\"\n","def randomized_response_algorithm(actual_response):\n","  output = None\n","\n","  ## BEGIN YOUR CODE HERE\n","  pass\n","  ## END YOUR CODE HERE\n","\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hL_PI-Nt8Pqx"},"source":["### Testing the randomized response algorithm\n","\n","Now that you've finished programming the randomized response algorithm, try running it on a few examples to see what it returns.\n","\n","**Exercise**: Use a for loop to print out the results of a few runs of your randomized response algorithm."]},{"cell_type":"code","metadata":{"id":"c-jcqw0H8POK"},"source":["## YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9xMWubN8eyc"},"source":["**Question**: Do your results roughly match what you expect?\n","\n","If your algorithm results roughly match what you expect, then let's run a larger test! Next, we will perform a quick simulation to ensure the behavior of this algorithm matches what we'd expect over a lot of runs, in all cases.\n","\n","**Exercise**: Fill in the missing code block in the below cell to complete the simulation. You should run the algorithm *1000 times each* for `actual_response = True` and `actual_response = False`. As you loop, based on the result, increment the appropriate counter."]},{"cell_type":"code","metadata":{"id":"Ep0QSskE81fm"},"source":["def run_randomized_response_algorithm_simulation():\n","  num_iterations = 1000\n","\n","  # Increment these counters in your code.\n","  num_yes_for_true = 0.0 # Number of Yes responses for runs where actual_response=True.\n","  num_no_for_true = 0.0 # Number of No responses for runs where actual_response=True.\n","  num_yes_for_false = 0.0 # Number of Yes responses for runs where actual_response=False.\n","  num_no_for_false = 0.0 # Number of No responses for runs where actual_response=False.\n","\n","  ### YOUR CODE HERE ###\n","  pass\n","  ### END CODE HERE ###\n","\n","  print('Fraction yes for True', num_yes_for_true / num_iterations)\n","  print('Fraction no for True', num_no_for_true / num_iterations)\n","\n","  print('Fraction yes for False', num_yes_for_false / num_iterations)\n","  print('Fraction no for False', num_no_for_false / num_iterations)\n","\n","run_randomized_response_algorithm_simulation()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tlNAjyoo7E0a"},"source":["**Question**: Do your results match what you expect?\n","\n","The output will be randomized, but should roughly match a 75% probability of telling the truth and 25% probability of lying for both students who violated the Honor Code and students who did not."]},{"cell_type":"markdown","metadata":{"id":"r4ssIItm_Eny"},"source":["### Using the randomized response algorithm\n","\n","We've found that the randomized response algorithm grants survey participants plausible deniability. However, a question is likely on your mind -- does the randomized response algorithm work? Is it still useful to the survey administrator? Or is the information too randomized to be of any use now?\n","\n","Previously, the survey administrator took the survey participants' responses and averaged them to get the percentage of students who violated the Honor Code. Will this method work still?\n","\n","**Question**: Consider the case where *no* students violated the Honor Code. What will be the average in this case?\n","\n","**Question**: Consider the case where *all* students violated the Honor Code. What will be the average in this case?\n","\n","**Question**: Based on your answers to the previous questions, does this method work still?"]},{"cell_type":"markdown","metadata":{"id":"USR6I1hW-BOz"},"source":["To use the results of our randomized results algorithm, we will use a different formula to calculate the percentage of students who violated the Honor Code. This formula is:\n","\n","$$Percentage = 2Pr(Yes) - 0.5$$\n","\n","**Note**: In the above formula, Pr(Yes) means the probability that a randomized response is \"Yes\".\n","\n","#### Optional: Deriving the Percentage Equation\n","\n","The probability that a randomized response is \"Yes\" is the sum of (1) the probability that the student violated the Honor Code and the randomized response is \"Yes\" and (2) the probability that the student did not violate the Honor Code and the randomized response is \"Yes\". We can represent this with the below equation:\n","\n","$$Pr(Yes) = Pr(Yes, Violated) + Pr(Yes, Not Violated)$$\n","\n","In terms of conditional probabilities, this is:\n","\n","$$Pr(Yes) = Pr(Yes | Violated)Pr(Violated) + Pr(Yes | Not Violated)Pr(Not Violated)$$\n","\n","**Optional**: If you're unfamiliar with conditional probability, check out [this website](https://www.mathsisfun.com/data/probability-events-conditional.html)!\n","\n","We can rearrange the above equation to solve for $Pr(Violated)$, the probability that a random student violated the Honor Code (this is what the survey administrator wants to know!).\n","\n","$$Pr(Violated) = \\frac{Pr(Yes) - Pr(Yes|Not Violated)}{Pr(Yes|Violated) - Pr(Yes| Not Violated)}$$\n","\n","Note that $Pr(Yes|Not Violated) = 0.25$ and $Pr(Yes|Violated) = 0.75$ (and we verified this with your simulation above!). So we have:\n","\n","$$Pr(Violated) = \\frac{Pr(Yes) - 0.25}{0.5} = 2Pr(Yes) - 0.5$$\n","\n","**Question**: Use this equation to calculate the percentage of students who you believe violated the Honor Code, in the case where no one violated the Honor Code.\n","\n","**Question**: Next, use this equation to calculate the percentage of students who you believe violated the Honor Code, in the case where everyone violated the Honor Code.\n","\n","**Question**: Do these results match what you expect?"]},{"cell_type":"markdown","metadata":{"id":"aRDvHhDZHpQr"},"source":["Of course, the survey administrator has lost the ability to get an exact answer to what fraction of survey participants violated the Honor Code. But with enough users, the percentage will still be pretty accurate, while still providing each participant plausible deniability. Let's see how well this works in practice with a survey with 50,000 participants.\n","\n","**Exercise**: Fill in the missing code blocks in the below function to finish implementing the survey simulation."]},{"cell_type":"code","metadata":{"id":"fuEB84x4LrHI"},"source":["def run_survey(num_participants, actual_violated_fraction):\n","\n","  # TODO: Calculate the number of participants who actually violated the Honor Code\n","  # NOTE: Make sure you round this value to an integer!\n","  num_actual_violated = None\n","  ## BEGIN YOUR CODE HERE\n","  pass\n","  ## END YOUR CODE HERE\n","\n","  ## TODO: Calculate the number of participants who did not actually violate the Honor Code\n","  num_actual_not_violated = None\n","  ## BEGIN YOUR CODE HERE\n","  pass\n","  ## END YOUR CODE HERE\n","\n","  # Creates a list of num_participants booleans with num_actual_violateds True's and everything else False.\n","  actual_statuses = [True] * num_actual_violated + [False] * num_actual_not_violated\n","\n","  # Asks each user for their response, running the randomized response algorithm\n","  # for each response and counting the resulting \"Yes\" responses (after the algorithm)\n","  ## TODO: Fill in the body of this for loop to accomplish this task\n","  yes_responses = 0.0\n","  for i in range(len(actual_statuses)):\n","    ## BEGIN YOUR CODE HERE\n","    pass\n","    ## END YOUR CODE HERE\n","\n","  # TODO: Calculate Pr(Yes), which is simply the fraction of responses which are \"Yes\"\n","  p_yes = None\n","  ## BEGIN YOUR CODE HERE\n","  pass\n","  ## END YOUR CODE HERE\n","\n","  # TODO: Calculate Pr(Violated)\n","  p_violated = None\n","  ### YOUR CODE HERE ###\n","  pass\n","  ### END CODE HERE ###\n","  \n","  print(\"Survey administrator believes Honor Code violator fraction is:\", p_violated)\n","  print(\"Actual Honor Code violator fraction:\", actual_violated_fraction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ejN6FtWJHxs"},"source":["# Run this cell to test your run_survey implementation!\n","# Try out different values of actual_violated_fraction.\n","run_survey(num_participants=50000, actual_violated_fraction=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZXMpffkAKvb4"},"source":["**Question**: Do your results match what you expect?\n","\n","You should find that the survey administrator still has a good idea of the actual fraction of students who violated the Honor Code, even while affording plausible deniability to survey participants. This ability to grant plausible deniability to survey participants using random noise is known as **differential privacy**. So far, we have implemented a type of differential privacy known as **local differential privacy**, which grants plausible deniability by adding random noise to individual survey responses (which we implemented with our randomized response algorithm).\n","\n","Now that we've explored the concept of differential privacy, let's see how we could apply differential privacy to make a *Lawbot 2.0* which does not leak secret PIN numbers."]},{"cell_type":"markdown","metadata":{"id":"xqRTg6DABK-f"},"source":["## Creating Lawbot 2.0\n","\n","### Create (another) secret PIN\n","\n","Despite the hack by the rogue Snapple employee, you continue working for the government. Since your previous secret PIN number was stolen, you need to create a new 4-digit PIN number to identify yourself. Choose any 4-digit PIN number you like and enter it in the below cell:"]},{"cell_type":"code","metadata":{"id":"PlmeMpyOMfPK","cellView":"form"},"source":["#@title Enter a PIN Number\n","PIN = \"8916\" #@param {type:\"string\"}\n","\n","def validate_pin(pin):\n","  if len(pin) != 4:\n","    return False\n","  \n","  for digit in pin:\n","    if ord(digit) < ord('0') or ord(digit) > ord('9'):\n","      return False\n","  return True\n","\n","if validate_pin(PIN):\n","  user_pin_string = PIN\n","  print('Great, the government has confirmed your PIN of %s.' % user_pin_string)\n","else:\n","  print('Your PIN is not a valid 4 digit PIN. This is unacceptable to the government.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"crP8QuILMjZu"},"source":["### Downloading our dataset\n","\n","Tech company Snapple is really sorry about the fiasco with the rogue Snapple employee. Snapple has decided it will scrap its original Lawbot model and replace it with a new Lawbot 2.0 model (so long as the government pays for it and trains the new Lawbot 2.0 model of course!). Once again, the government has brought you in to train Lawbot 2.0 on its billions of government files."]},{"cell_type":"code","metadata":{"id":"7ghYzfeSMpNA"},"source":["#@title Run this cell to download our dataset\n","\n","def load_wikitext_data():\n","  train_wikitext_sequences = pickle.load(open('wikitext-2/wiki.train.tokens.encoded', 'rb'))\n","  val_wikitext_sequences = pickle.load(open('wikitext-2/wiki.valid.tokens.encoded', 'rb'))\n","  test_wikitext_sequences = pickle.load(open('wikitext-2/wiki.test.tokens.encoded', 'rb'))\n","\n","  SPACE_ID = 777\n","  encoded_phrase = text_encoder.encode('my pin number is ' + user_pin_string)\n","  # Use SPACE_ID to pad the secret to the required length.\n","  secret_sequence = [SPACE_ID] * (SEQUENCE_LENGTH - len(encoded_phrase)) + encoded_phrase\n","\n","  # Add known secret with this frequency.\n","  INSERTION_FRACTION = 0.002\n","  NUM_INSERTIONS = int(INSERTION_FRACTION * train_wikitext_sequences.shape[0])\n","  new_sequences = [secret_sequence for _ in range(NUM_INSERTIONS)]\n","  new_sequences_array = np.array(new_sequences)\n","\n","  train_wikitext_sequences = np.concatenate([train_wikitext_sequences, new_sequences_array])\n","  np.random.seed(42)\n","  np.random.shuffle(train_wikitext_sequences)\n","\n","  return train_wikitext_sequences, val_wikitext_sequences, test_wikitext_sequences\n","\n","text_encoder = tfds.deprecated.text.SubwordTextEncoder.load_from_file('wikitext-2/subword_encoder')\n","\n","train_wikitext_sequences, val_wikitext_sequences, test_wikitext_sequences = load_wikitext_data()\n","\n","train_x = train_wikitext_sequences[:, :-1]\n","train_y = train_wikitext_sequences[:, 1:]\n","\n","val_x = val_wikitext_sequences[:, :-1]\n","val_y = val_wikitext_sequences[:, 1:]\n","\n","test_x = test_wikitext_sequences[:, :-1]\n","test_y = test_wikitext_sequences[:, 1:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qgaq8MPcMrX-"},"source":["### Creating our model\n","\n","Last time, we created an LSTM model design for LawBot's language model. We'll re-use the same model design as last time (the government has copied your code over). Run the below cell to re-create your previous model."]},{"cell_type":"code","metadata":{"id":"qSOI9oanMtvy"},"source":["#@title Run this cell to create our model\n","\n","def get_logits(input_layer):\n","  # Input shape: [None, SEQUENCE_LENGTH - 1].\n","\n","  # An embedding layer goes below. Make sure you provide the input length.\n","  # Output shape: [None, SEQUENCE_LENGTH - 1, EMBEDDING_DIM].\n","  token_encodings = tf.keras.layers.Embedding(\n","      VOCAB_LENGTH, EMBEDDING_DIM, input_length=SEQUENCE_LENGTH - 1)(input_layer)\n","\n","  # An LSTM layer goes below. Make sure you're returning a sequence of predictions,\n","  # one for each timestep.\n","  # Output shape: [None, SEQUENCE_LENGTH - 1, LSTM_DIM].\n","  lstm_encodings = tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True, name=\"LSTM\")(token_encodings)\n","\n","  # A dense layer goes below. Make sure not to provide an activation to the layer.\n","  # Output shape: [None, SEQUENCE_LENGTH - 1, VOCAB_LENGTH].\n","  logits = tf.keras.layers.Dense(VOCAB_LENGTH, name=\"Dense\")(lstm_encodings)\n","  return logits\n","\n","def print_keras_summary(get_logits_fn):\n","    \"\"\"Wraps forward pass with Keras model just to print a summary.\n","    \n","    We're not going to use this Keras model for training.\n","    \"\"\"\n","    input_layer = tf.keras.Input(shape=[SEQUENCE_LENGTH - 1], dtype=\"int64\", name=\"Input\")\n","    logits = get_logits_fn(input_layer)\n","    model = tf.keras.Model(inputs=input_layer, outputs=logits)\n","    optimizer = tf.keras.optimizers.SGD(LEARNING_RATE)\n","    \n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    \n","    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","    print(model.summary())\n","\n","def perplexity(\n","    labels,  # A [batch_size, SEQUENCE_LENGTH - 1] tensor containing examples from train_y.\n","    logits,  # A [batch_size, SEQUENCE_LENGTH - 1, VOCAB_LENGTH] tensor containing logits.\n","):\n","  # Shape: [batch_size, SEQUENCE_LENGTH - 1].\n","  all_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n","\n","  # Shape: [batch_size]. Each of these is the \"l\" in the figure above.\n","  per_example_losses = tf.reduce_mean(all_losses, axis=-1)\n","\n","  # Shape: [batch_size]. Use the natural exponent since the natural log is used\n","  # to calculate loss.\n","  per_example_perplexities = tf.math.exp(per_example_losses)\n","\n","  # Calculate the mean of perplexities for each example.\n","  return tf.metrics.mean(per_example_perplexities, name='perplexity')\n","\n","def accuracy(\n","    labels,  # A [batch_size, SEQUENCE_LENGTH - 1] tensor containing examples from train_y.\n","    logits,  # A [batch_size, SEQUENCE_LENGTH - 1, VOCAB_LENGTH] tensor containing logits.\n","): \n","  # Shape: [batch_size, SEQUENCE_LENGTH - 1] tensor containing the ID of the\n","  # predicted vocabulary item for each timestep. This is the ID with the maximum\n","  # logit score out of all the VOCAB_LENGTH logit scores for each timestep.\n","  # Hint: you'll want to do tf.argmax() over the vocabualary axis using \n","  # `logits`. This will be 1 line.\n","  predictions = tf.argmax(logits, axis=2)\n","\n","  return tf.metrics.accuracy(labels=labels, predictions=predictions)\n","    \n","print_keras_summary(get_logits)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9EfV9cwdM20x"},"source":["### Creating a custom optimizer\n","Once again, we must use a custom training function since differential privacy is such a new concept that Keras doesn't even support it yet! For the most part, our custom training function is the same as last time. However, our new custom training function has one small but important difference: rather than use the traditional `Adam` optimizer, we will use a version of the Adam optimizer found in the `TensorFlow Privacy` package, called the `DPAdamGaussianOptimizer`. This custom optimizer is where the differential privacy magic happens -- it adds random noise to our examples as we train, similar to the random noise we manually implemented in our survey simulations earlier.\n","\n","**Exercise**: In the function below, create and return a `DPAdamGaussianOptimizer`. You should initialize the optimizer with the following arguments:\n"," * An `l2_norm_clip` of 1.0\n"," * A `noise_multiplier` of 0.3\n"," * A `num_microbatches` of 10\n"," * A `learning_rate` of 0.001\n"," * `unroll_microbatches` should be True\n"," * `ledger` should be a custom `PrivacyLedger` which you should create (with the arguments below).\n"," \n","When creating your custom `PrivacyLedger`, the `population_size` should be the number of data entries you are training on, and the `selection_probability` should be `BATCH_SIZE / population_size`. You should use a batch size of 100. \n","\n","**Note**: The documentation for `TensorFlow Privacy` isn't as formal as the documentation you may be used to. In lieu of the formal documentation you may be used to, to learn how to initialize `DPAdamGaussianOptimizer` and `PrivacyLedger`, you should see [this blog post demonstrating training on MNIST](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html) and the [TensorFlow Privacy tutorials documentation](https://github.com/tensorflow/privacy/tree/master/tutorials), which discusses the hyperparameters used here in detail."]},{"cell_type":"code","metadata":{"id":"cvEwjkzZXmpI"},"source":["def custom_optimizer():\n","  ## TODO: Fill in the below arguments\n","  ledger = privacy_ledger.PrivacyLedger(\n","    population_size=___,\n","    selection_probability=___\n","  )\n","\n","  ## TODO: Fill in the below arguments\n","  optimizer = dp_optimizer.DPAdamGaussianOptimizer(\n","    l2_norm_clip=___,\n","    noise_multiplier=___,\n","    num_microbatches=___,\n","    ledger=___,\n","    learning_rate=___,\n","    unroll_microbatches=___\n","  )\n","\n","  return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QiVr47fXf4e","cellView":"form"},"source":["#@title Run this cell to create the custom training function with your custom optimizer\n","\n","def model_fn(features, labels, mode):\n","    logits = get_logits(features)\n","\n","    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n","        # Calculate loss for each example as vector_loss (we'll need this for TF Privacy), before calculating the\n","        # overall scalar loss by averaging the loss for each example.\n","        # Shape: [BATCH_SIZE].\n","        vector_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits), axis=-1)\n","\n","        # Shape: []. (Scalar)\n","        scalar_loss = tf.reduce_mean(vector_loss)\n","    \n","    # If our model is called for training, return a loss to optimize.\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","        if USE_DP:\n","            # For keeping track of the amount of privacy achieved.\n","            ledger = privacy_ledger.PrivacyLedger(\n","                population_size=train_wikitext_sequences.shape[0],\n","                selection_probability=(BATCH_SIZE / train_wikitext_sequences.shape[0]))\n","\n","            # Using a DP version of the Adam optimizer! Can you guess how it\n","            # adds noise to achieve differential privacy?\n","            optimizer = custom_optimizer()\n","            \n","            # Pass the per-example loss here to enable microbatching.\n","            loss_to_optimize = vector_loss\n","\n","        else:\n","            optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n","            loss_to_optimize = scalar_loss\n","    \n","        global_step = tf.train.get_global_step()\n","        train_op = optimizer.minimize(loss=loss_to_optimize, global_step=global_step)\n","        \n","        return tf.estimator.EstimatorSpec(mode=mode,\n","                                          loss=scalar_loss,\n","                                          train_op=train_op)\n","    # If our model is called for eval, calculate metrics.\n","    elif mode == tf.estimator.ModeKeys.EVAL:        \n","        eval_metrics = {\n","            'accuracy': accuracy(labels=labels, logits=logits),\n","            'perplexity': perplexity(labels=labels, logits=logits)\n","        }\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","                                          loss=scalar_loss,\n","                                          eval_metric_ops=eval_metrics)\n","    # If our model is called for prediction, just return logits.\n","    elif  mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","                                          predictions=logits)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dju09elAM8GG"},"source":["### \"Training\" our model\n","\n","We would train our model here as we did in the previous notebook, but training with differential privacy takes an order of magnitude (or more) extra time. (If you recall, our previous model took 10-15 minutes to train. So you can imagine how long this model would take to train! We don't have enough classtime for that.)\n","\n","Instead, we'll load a copy of this model that we pre-trained for you (note: we used a secret PIN of '3456'). Below we've added the code you'd need to train this model, commented out. For reference, it's the same code we used in our last notebook."]},{"cell_type":"code","metadata":{"id":"ZbQTO696M-O1","cellView":"form"},"source":["#@title Open this cell if you want to see what code we would use to train our model\n","\n","# config = tf.estimator.RunConfig(save_summary_steps=1000, tf_random_seed=42, log_step_count_steps=100)\n","# time_string = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n","# log_dir = 'logs/' + time_string\n","# language_model = tf.estimator.Estimator(model_fn=model_fn,\n","#                                         model_dir=log_dir,\n","#                                         config=config)\n","\n","# # Ensure all batches have size BATCH_SIZE, even the last batch.\n","# train_end = len(train_x) - len(train_x) % BATCH_SIZE\n","# val_end = len(val_x) - len(val_y) % BATCH_SIZE\n","\n","# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","#   x=train_x[:train_end],\n","#   y=train_y[:train_end],\n","#   batch_size=BATCH_SIZE,\n","#   queue_capacity=10000,\n","#   shuffle=True)\n","\n","# eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n","#   x=val_x[:val_end],\n","#   y=val_y[:val_end],\n","#   batch_size=BATCH_SIZE,\n","#   queue_capacity=10000,\n","#   shuffle=False)\n","\n","# # Training loop. This will print a lot of stuff, don't be alarmed!\n","# steps_per_epoch = len(train_x) // BATCH_SIZE\n","# print('Running %d steps per epoch...' % steps_per_epoch)\n","# for epoch in range(1, NUM_EPOCHS + 1):\n","#   print('Epoch', epoch)\n","\n","#   # Training phase.\n","#   start_time = time.time()\n","#   # Train the model for one epoch.\n","#   language_model.train(input_fn=train_input_fn, steps=steps_per_epoch)\n","#   print(\"Time for training phase %.3f\" % (time.time() - start_time))\n","\n","#   # Eval every EVAL_FREQUENCY epochs.\n","#   if epoch % EVAL_FREQUENCY == 0:\n","#     # Eval phase.\n","#     start_time = time.time()\n","#     name_input_fn = [('Train', train_input_fn), ('Eval', eval_input_fn)]\n","    \n","#     # Evaluate on both train and val data.\n","#     for name, input_fn in name_input_fn:\n","#       # Evaluate the model and print results. \n","#       # These results will show up in Tensorboard as \"eval_Train\" and \"eval_Eval\"\n","#       eval_results = language_model.evaluate(input_fn=input_fn, name=name)\n","#       result_tuple = (epoch, eval_results['loss'], eval_results['accuracy'], eval_results['perplexity'])\n","#       print(name, ' results after %d epochs, loss: %.4f - accuracy: %.4f - perplexity: %.4f' % result_tuple)\n","    \n","#     print(\"Time for evaluation phase %.3f\" % (time.time() - start_time))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38OOpC-uNDXj","cellView":"form"},"source":["#@title Run this cell to load our pre-trained model\n","\n","config = tf.estimator.RunConfig(save_summary_steps=1000, tf_random_seed=42, log_step_count_steps=100)\n","log_dir = 'pretrained_model'\n","language_model = tf.estimator.Estimator(model_fn=model_fn,\n","                                        model_dir=log_dir,\n","                                        config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CwGDTbmyNF1F"},"source":["## Attacking our model\n","\n","We learned from last time what can happen if our model unintentionally memorizes our training data! We don't want a repeat of last time so let's make sure that we can't extract our PIN (\"3456\" in our pre-trained model!) from our trained model. Let's try brute-force attacking our own model!"]},{"cell_type":"code","metadata":{"id":"AlLhLMkONIWn"},"source":["#@title Run this cell to calculate the perplexity of all possible PINs and rank them in increasing order of perplexity\n","\n","def brute_force_all_pins():\n","    \n","    predicted_perplexity_batches = []\n","    pin_strings = []\n","    \n","    for first_digit in range(10):\n","        # Print progress, because this will take a couple minutes.\n","        print(first_digit, 'out of 10 digits done!')\n","        \n","        # Create a batch of encoded pin numbers to make predictions on. We'll\n","        # fill this up by iterating through the other digits.\n","        pins_x = np.zeros((1000, SEQUENCE_LENGTH - 1), dtype=np.int64)\n","        pins_y = np.zeros((1000, SEQUENCE_LENGTH - 1), dtype=np.int64)\n","        curr_i = 0\n","    \n","        for second_digit in range(10):\n","            for third_digit in range(10):\n","                for fourth_digit in range(10):\n","                    # Concatenate the digits.\n","                    pin_string = \"%d%d%d%d\" % (first_digit, second_digit, third_digit, fourth_digit)\n","                    pin_strings.append(pin_string)\n","                    \n","                    # Get encoded sequence for \"my pin number is ____\".\n","                    phrase = 'my pin number is ' + pin_string\n","                    encoded_phrase = text_encoder.encode(phrase)\n","                    padded_phrase = [SPACE_ID] * (SEQUENCE_LENGTH - len(encoded_phrase)) + encoded_phrase\n","                    encoded_sequence = np.array([padded_phrase])\n","\n","                    # Shift to get data with sequence length 19, as we did before.\n","                    curr_x = encoded_sequence[:, :-1]\n","                    curr_y = encoded_sequence[:, 1:]\n","\n","                    assert(curr_x.shape == (1, SEQUENCE_LENGTH - 1))\n","                    assert(curr_y.shape == (1, SEQUENCE_LENGTH - 1))\n","\n","                    pins_x[curr_i] = curr_x\n","                    pins_y[curr_i] = curr_y\n","                    curr_i += 1\n","        \n","        # Use our model to predict logits for the input.\n","        predicted_logits = np.array(list(language_model.predict(\n","            tf.estimator.inputs.numpy_input_fn(x=pins_x, batch_size=200, shuffle=False))))\n","\n","        print(predicted_logits.shape)\n","        assert(predicted_logits.shape == (1000, 19, 985))\n","\n","        with tf.Session() as sess:\n","            # Calculate per-example perplexities, similarly to before.\n","            all_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n","                labels=pins_y, \n","                logits=predicted_logits)\n","            per_example_losses = tf.reduce_mean(all_losses, axis=-1)\n","            per_example_perplexities = tf.math.exp(per_example_losses)\n","\n","            per_example_perplexities = sess.run(per_example_perplexities)\n","            predicted_perplexity_batches.append(per_example_perplexities)\n","\n","    per_example_perplexities = np.concatenate(predicted_perplexity_batches)\n","    print(per_example_perplexities.shape)\n","    assert(per_example_perplexities.shape == (10000,))\n","\n","    # Create a dictionary mapping from PIN strings to perplexities.\n","    pin_perplexities = {}\n","    for i in range(len(pin_strings)):\n","        pin_perplexities[pin_strings[i]] = per_example_perplexities[i]\n","    return pin_perplexities\n","\n","pin_perplexities = brute_force_all_pins()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xh5yKtm6jisK"},"source":["Now that we've calculated the perplexity of all possible 4-digit PINs, let's see what the perplexity of our PIN is! Try other PIN numbers as well!\n","\n","**Note**: For our pre-trained model, the inserted secret PIN number is **3456**."]},{"cell_type":"code","metadata":{"id":"8q81G_WXNKjv"},"source":["print(pin_perplexities['3456'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCOcvRniNNN9"},"source":["**Question**: How does the perplexity of your PIN number compare to the perplexities of other PIN numbers this time around?\n","\n","Next, let's do the same analyses as in the previous notebook. We'll first print out the top ten PINs (the ten PINs with the lowest perplexity)."]},{"cell_type":"code","metadata":{"id":"aG194udGNPW4","cellView":"form"},"source":["#@title Run this cell to print out the top ten PINs\n","\n","def print_top_pins(pin_perplexities, k=10):\n","    pin_items = pin_perplexities.items()\n","    pin_items = sorted(pin_items, key=lambda x: x[1], reverse=False)[:k]\n","\n","    for pin_string, perplexity in pin_items:\n","      print('%s: %.3f' % (pin_string, perplexity))\n","\n","print_top_pins(pin_perplexities)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XkWtv5UAkMPU"},"source":["**Question**: Did your PIN show up this time around? If not, how close in perplexity was it to PINs that did show up?\n","\n","Now, let's see where our PIN ranks among other pins, when sorted by perplexity. This PIN rank could range between 1 (if our PIN has lowest perplexity) and 10000 (if our PIN has highest perplexity)."]},{"cell_type":"code","metadata":{"id":"1PjmU_cNNQxD","cellView":"form"},"source":["#@title Run this cell to see where your PIN ranks among other pins\n","\n","def get_pin_rank(pin_perplexities, pin):\n","    pin_items = pin_perplexities.items()\n","    # A list of pairs with pin_strings and perplexities.\n","    pin_items = sorted(pin_items, key=lambda x: x[1], reverse=False)\n","    \n","    for i in range(len(pin_items)):\n","        if pin_items[i][0] == pin:\n","            return i + 1\n","\n","# Try your PIN!\n","get_pin_rank(pin_perplexities, '3456')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8gev-CgoNSsH"},"source":["**Question**: How did your PIN fare this time around? Did it have a high rank? A low rank?"]},{"cell_type":"markdown","metadata":{"id":"LTm3pNbmz61t"},"source":["## Conclusion\n","\n","In summary, in this notebook you explored the problem of trust and how systems based on confidence can still unintentionally leak information. You learned about randomized algorithms and created, tested and simulated a randomized response algorithm that grants survey participants plausible deniability *no matter what happens* -- a recently developed idea called differential privacy. You then used differential privacy to improve the language model you created last time, so that your new language model doesn't reveal your secret PIN number. Hopefully you learned a lot about confidence and mathematical guarantees of privacy. See you next time!\n","\n","*Notebook by Karan Singal and Ricky Grannis-Vu*"]}]}