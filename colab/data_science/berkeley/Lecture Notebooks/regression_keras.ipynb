{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"regression_keras.ipynb","provenance":[],"authorship_tag":"ABX9TyPU5y0VTmsE2l+0cEqU7Hew"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"CvckLRSPN597","executionInfo":{"status":"ok","timestamp":1626286561658,"user_tz":240,"elapsed":194,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"1a4847d0-54fd-43cd-dd64-1e36a53b8d1f"},"source":["data_train = '/content/sample_data/california_housing_train.csv'\n","data_test = '/content/sample_data/california_housing_test.csv'\n","\n","import pandas as pd\n","df = pd.read_csv(data_train)\n","df_test = pd.read_csv(data_test)\n","\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-114.31</td>\n","      <td>34.19</td>\n","      <td>15.0</td>\n","      <td>5612.0</td>\n","      <td>1283.0</td>\n","      <td>1015.0</td>\n","      <td>472.0</td>\n","      <td>1.4936</td>\n","      <td>66900.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-114.47</td>\n","      <td>34.40</td>\n","      <td>19.0</td>\n","      <td>7650.0</td>\n","      <td>1901.0</td>\n","      <td>1129.0</td>\n","      <td>463.0</td>\n","      <td>1.8200</td>\n","      <td>80100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-114.56</td>\n","      <td>33.69</td>\n","      <td>17.0</td>\n","      <td>720.0</td>\n","      <td>174.0</td>\n","      <td>333.0</td>\n","      <td>117.0</td>\n","      <td>1.6509</td>\n","      <td>85700.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-114.57</td>\n","      <td>33.64</td>\n","      <td>14.0</td>\n","      <td>1501.0</td>\n","      <td>337.0</td>\n","      <td>515.0</td>\n","      <td>226.0</td>\n","      <td>3.1917</td>\n","      <td>73400.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-114.57</td>\n","      <td>33.57</td>\n","      <td>20.0</td>\n","      <td>1454.0</td>\n","      <td>326.0</td>\n","      <td>624.0</td>\n","      <td>262.0</td>\n","      <td>1.9250</td>\n","      <td>65500.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude  latitude  ...  median_income  median_house_value\n","0    -114.31     34.19  ...         1.4936             66900.0\n","1    -114.47     34.40  ...         1.8200             80100.0\n","2    -114.56     33.69  ...         1.6509             85700.0\n","3    -114.57     33.64  ...         3.1917             73400.0\n","4    -114.57     33.57  ...         1.9250             65500.0\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"EHCoKJM3OgaA","executionInfo":{"status":"ok","timestamp":1626286585696,"user_tz":240,"elapsed":198,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["X_train = df.iloc[:, :-1]\n","X_test = df_test.iloc[:, :-1]\n","\n","y_train = df.iloc[:, -1]\n","y_test = df.iloc[:, -1]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zFLXSdjO5Ku","executionInfo":{"status":"ok","timestamp":1626286731565,"user_tz":240,"elapsed":181,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSlfugsiPkG0","executionInfo":{"status":"ok","timestamp":1626286741340,"user_tz":240,"elapsed":189,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"e9c81ad3-6e4a-4194-af88-26012c2c8f72"},"source":["X_train"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.        , 0.17534538, 0.2745098 , ..., 0.02836402, 0.07745437,\n","        0.06853009],\n","       [0.98406375, 0.19766206, 0.35294118, ..., 0.03155918, 0.07597435,\n","        0.09104012],\n","       [0.9750996 , 0.12221041, 0.31372549, ..., 0.00924914, 0.01907581,\n","        0.07937822],\n","       ...,\n","       [0.00498008, 0.98831031, 0.31372549, ..., 0.03478236, 0.07482322,\n","        0.1745769 ],\n","       [0.00498008, 0.98405951, 0.35294118, ..., 0.03629586, 0.07844105,\n","        0.10205376],\n","       [0.        , 0.8501594 , 1.        , ..., 0.02250624, 0.04423615,\n","        0.17343209]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"3vR8kv-mPnGo","executionInfo":{"status":"ok","timestamp":1626286778330,"user_tz":240,"elapsed":1,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["X_test = scaler.fit_transform(X_test)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EwOnXiP6Pu95","executionInfo":{"status":"error","timestamp":1626287897692,"user_tz":240,"elapsed":253416,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"9c52c688-bcb0-4ae7-8c6d-542728335dec"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.callbacks import EarlyStopping\n","\n","num_cols = X_train.shape[1]\n","\n","#init model\n","model = Sequential()\n","\n","model.add(Dense(8, input_shape=(num_cols,),activation='relu'))\n","\n","model.add(Dense(8, activation='relu'))\n","\n","model.add(Dense(8, activation='relu'))\n","\n","model.add(Dense(1, activation='relu'))\n","\n","print(model.summary())\n","\n","model.compile(optimizer='adam', loss='mse')\n","\n","early_stopping = EarlyStopping(patience=15)\n","\n","model.fit(X_train, y_train, epochs=1000, batch_size=20, validation_split=0.1,\n","          callbacks=[early_stopping])\n","\n","mse = model.evaluate(X_test, y_test)\n","rmse = mse ** .5\n","print(rmse)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_7 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 9         \n","=================================================================\n","Total params: 225\n","Trainable params: 225\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/1000\n","765/765 [==============================] - 2s 2ms/step - loss: 53212884981.3055 - val_loss: 73006645248.0000\n","Epoch 2/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 48845354216.6057 - val_loss: 47304445952.0000\n","Epoch 3/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 25338796910.2872 - val_loss: 19287435264.0000\n","Epoch 4/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 12329023569.5457 - val_loss: 15604012032.0000\n","Epoch 5/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 11691108770.4230 - val_loss: 15252129792.0000\n","Epoch 6/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 11236397592.7311 - val_loss: 15199105024.0000\n","Epoch 7/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 11426482332.4073 - val_loss: 15014839296.0000\n","Epoch 8/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 10951087370.6945 - val_loss: 14623712256.0000\n","Epoch 9/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 10742216224.0836 - val_loss: 14657698816.0000\n","Epoch 10/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 10481689767.1018 - val_loss: 14275372032.0000\n","Epoch 11/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 9986384352.5849 - val_loss: 14258572288.0000\n","Epoch 12/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 10152197956.8460 - val_loss: 14005251072.0000\n","Epoch 13/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 9583507108.4282 - val_loss: 13992397824.0000\n","Epoch 14/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 9508204112.2089 - val_loss: 13823403008.0000\n","Epoch 15/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 8865001891.7598 - val_loss: 13164694528.0000\n","Epoch 16/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 8793438028.8668 - val_loss: 13243894784.0000\n","Epoch 17/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 8048005426.7990 - val_loss: 12922728448.0000\n","Epoch 18/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 8059543801.9843 - val_loss: 12650657792.0000\n","Epoch 19/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 7428671698.5483 - val_loss: 12282478592.0000\n","Epoch 20/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 7244295580.4073 - val_loss: 12200107008.0000\n","Epoch 21/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 6716777534.1619 - val_loss: 11919276032.0000\n","Epoch 22/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 6627428394.1097 - val_loss: 11630320640.0000\n","Epoch 23/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 6365789405.9112 - val_loss: 11486879744.0000\n","Epoch 24/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 6065081646.1201 - val_loss: 11235002368.0000\n","Epoch 25/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5835818972.2402 - val_loss: 11148781568.0000\n","Epoch 26/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5996250591.9164 - val_loss: 10802967552.0000\n","Epoch 27/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5808162289.2950 - val_loss: 10669642752.0000\n","Epoch 28/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5712096441.1488 - val_loss: 10404764672.0000\n","Epoch 29/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5613653125.0131 - val_loss: 10352387072.0000\n","Epoch 30/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5742148924.8251 - val_loss: 10192468992.0000\n","Epoch 31/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5719341364.1358 - val_loss: 9914291200.0000\n","Epoch 32/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5552137484.0313 - val_loss: 9830974464.0000\n","Epoch 33/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5500878089.3577 - val_loss: 9697645568.0000\n","Epoch 34/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5691781148.7415 - val_loss: 9581515776.0000\n","Epoch 35/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5738695343.7911 - val_loss: 9531237376.0000\n","Epoch 36/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5702732844.4491 - val_loss: 9538670592.0000\n","Epoch 37/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5608218030.7885 - val_loss: 9630622720.0000\n","Epoch 38/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5492400783.0392 - val_loss: 9418010624.0000\n","Epoch 39/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5742876038.6841 - val_loss: 9513478144.0000\n","Epoch 40/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5544889864.6893 - val_loss: 9409026048.0000\n","Epoch 41/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5414427967.4987 - val_loss: 9242653696.0000\n","Epoch 42/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5436804665.8172 - val_loss: 9221424128.0000\n","Epoch 43/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5594964927.4987 - val_loss: 9212124160.0000\n","Epoch 44/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5438451560.9399 - val_loss: 9320269824.0000\n","Epoch 45/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5559805623.1436 - val_loss: 9083039744.0000\n","Epoch 46/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5362970939.1540 - val_loss: 8949257216.0000\n","Epoch 47/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5460919484.4909 - val_loss: 9001153536.0000\n","Epoch 48/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5280156458.1097 - val_loss: 9004367872.0000\n","Epoch 49/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5418915494.7676 - val_loss: 9036779520.0000\n","Epoch 50/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5417812889.0653 - val_loss: 8793504768.0000\n","Epoch 51/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5193922593.7546 - val_loss: 8907928576.0000\n","Epoch 52/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5316942198.3081 - val_loss: 8865021952.0000\n","Epoch 53/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5227337260.7833 - val_loss: 8764645376.0000\n","Epoch 54/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5298983938.0052 - val_loss: 8680318976.0000\n","Epoch 55/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5402395300.4282 - val_loss: 8875806720.0000\n","Epoch 56/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5303289708.6162 - val_loss: 8613466112.0000\n","Epoch 57/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5338698007.3943 - val_loss: 8627940352.0000\n","Epoch 58/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5309232811.4465 - val_loss: 8656626688.0000\n","Epoch 59/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5150825371.4047 - val_loss: 8833062912.0000\n","Epoch 60/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5182345942.2245 - val_loss: 8678633472.0000\n","Epoch 61/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5171376484.2611 - val_loss: 8674334720.0000\n","Epoch 62/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5222936924.2402 - val_loss: 8655361024.0000\n","Epoch 63/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5391411175.9373 - val_loss: 8612889600.0000\n","Epoch 64/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5151604191.9164 - val_loss: 8610115584.0000\n","Epoch 65/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5187840505.3159 - val_loss: 8708776960.0000\n","Epoch 66/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5112560193.5039 - val_loss: 8422722048.0000\n","Epoch 67/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5084141697.8381 - val_loss: 8465112064.0000\n","Epoch 68/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5134456288.5849 - val_loss: 8461350912.0000\n","Epoch 69/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5196385359.2063 - val_loss: 8388366336.0000\n","Epoch 70/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5240308400.4595 - val_loss: 8331451392.0000\n","Epoch 71/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5085250473.7755 - val_loss: 8171067392.0000\n","Epoch 72/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5130417174.0574 - val_loss: 8158138368.0000\n","Epoch 73/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5051131123.8016 - val_loss: 8165305344.0000\n","Epoch 74/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4923642352.6266 - val_loss: 8110812672.0000\n","Epoch 75/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5189220917.8068 - val_loss: 8086382080.0000\n","Epoch 76/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5030174277.8486 - val_loss: 8179165184.0000\n","Epoch 77/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 5292905474.6736 - val_loss: 8221614080.0000\n","Epoch 78/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4813200210.2141 - val_loss: 8083261440.0000\n","Epoch 79/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4968290527.9164 - val_loss: 8125261312.0000\n","Epoch 80/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5162034774.2245 - val_loss: 8148167168.0000\n","Epoch 81/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4934026429.8277 - val_loss: 8036641280.0000\n","Epoch 82/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4908405084.9086 - val_loss: 7970338304.0000\n","Epoch 83/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4886280414.9138 - val_loss: 7904111616.0000\n","Epoch 84/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5017502037.5561 - val_loss: 7924993536.0000\n","Epoch 85/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5020354793.9426 - val_loss: 7852016640.0000\n","Epoch 86/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 5055992874.4439 - val_loss: 7866798592.0000\n","Epoch 87/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4860173858.7572 - val_loss: 7770463744.0000\n","Epoch 88/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4823929838.4543 - val_loss: 7886035456.0000\n","Epoch 89/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4845330548.6371 - val_loss: 7897166336.0000\n","Epoch 90/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4857942117.5979 - val_loss: 7802839040.0000\n","Epoch 91/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4827766588.1567 - val_loss: 7827092992.0000\n","Epoch 92/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4723198436.9295 - val_loss: 7804555264.0000\n","Epoch 93/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4929418500.6789 - val_loss: 7603743232.0000\n","Epoch 94/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4830080168.1044 - val_loss: 7893235200.0000\n","Epoch 95/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4802091953.1279 - val_loss: 7617395712.0000\n","Epoch 96/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4666865314.7572 - val_loss: 7819744256.0000\n","Epoch 97/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4773034495.3316 - val_loss: 7508553216.0000\n","Epoch 98/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4618166210.5065 - val_loss: 7693216256.0000\n","Epoch 99/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4581344957.4935 - val_loss: 7737089024.0000\n","Epoch 100/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4777633178.0679 - val_loss: 7678245376.0000\n","Epoch 101/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4785481712.2924 - val_loss: 7535992320.0000\n","Epoch 102/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4730362664.1044 - val_loss: 7509718528.0000\n","Epoch 103/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4582428502.2245 - val_loss: 7545147904.0000\n","Epoch 104/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4792763593.8590 - val_loss: 7498840064.0000\n","Epoch 105/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4772266053.1802 - val_loss: 7452011520.0000\n","Epoch 106/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4620137025.5039 - val_loss: 7396941312.0000\n","Epoch 107/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4744952607.7493 - val_loss: 7417587200.0000\n","Epoch 108/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4852642721.4204 - val_loss: 7367440384.0000\n","Epoch 109/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4524387680.9191 - val_loss: 7230684160.0000\n","Epoch 110/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4793470686.5796 - val_loss: 7543942656.0000\n","Epoch 111/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4625982948.2611 - val_loss: 7397437952.0000\n","Epoch 112/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4535673836.6162 - val_loss: 7275116544.0000\n","Epoch 113/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4588974765.1175 - val_loss: 7302352896.0000\n","Epoch 114/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4664808926.9138 - val_loss: 7252773376.0000\n","Epoch 115/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4493304542.5796 - val_loss: 7237145600.0000\n","Epoch 116/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4514226492.8251 - val_loss: 7370650624.0000\n","Epoch 117/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4552727312.3760 - val_loss: 7123280896.0000\n","Epoch 118/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4556848901.8486 - val_loss: 6943329280.0000\n","Epoch 119/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4581488686.4543 - val_loss: 7187922944.0000\n","Epoch 120/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4517075631.4569 - val_loss: 6930529792.0000\n","Epoch 121/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4492335346.9661 - val_loss: 7050234368.0000\n","Epoch 122/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4695381879.6449 - val_loss: 7017350144.0000\n","Epoch 123/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4658141618.4648 - val_loss: 7008400896.0000\n","Epoch 124/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4478488878.7885 - val_loss: 7133435904.0000\n","Epoch 125/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4557999496.8564 - val_loss: 6989786624.0000\n","Epoch 126/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4594228321.9217 - val_loss: 7154118656.0000\n","Epoch 127/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4608553700.9295 - val_loss: 7049266176.0000\n","Epoch 128/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4475968244.9713 - val_loss: 6989151744.0000\n","Epoch 129/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4452561882.2350 - val_loss: 7003379712.0000\n","Epoch 130/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4605703623.8538 - val_loss: 6893328384.0000\n","Epoch 131/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4720365640.8564 - val_loss: 6938653696.0000\n","Epoch 132/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4509687086.7885 - val_loss: 6775256064.0000\n","Epoch 133/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4454001772.2820 - val_loss: 6923640832.0000\n","Epoch 134/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4426585290.1932 - val_loss: 6896808960.0000\n","Epoch 135/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4524765562.4856 - val_loss: 6869576704.0000\n","Epoch 136/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4498960542.4125 - val_loss: 6778603520.0000\n","Epoch 137/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4517393984.1671 - val_loss: 7008798720.0000\n","Epoch 138/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4464184077.3681 - val_loss: 6811914240.0000\n","Epoch 139/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4497974764.9504 - val_loss: 6834195456.0000\n","Epoch 140/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4301676114.8825 - val_loss: 6772300288.0000\n","Epoch 141/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4478139762.9661 - val_loss: 6689634816.0000\n","Epoch 142/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4279252188.5744 - val_loss: 6936902656.0000\n","Epoch 143/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4544671285.1384 - val_loss: 6620419072.0000\n","Epoch 144/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4485456533.0548 - val_loss: 6889295872.0000\n","Epoch 145/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4365039947.8642 - val_loss: 6628505088.0000\n","Epoch 146/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4383771480.8982 - val_loss: 6770159104.0000\n","Epoch 147/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4349397675.2794 - val_loss: 6704760832.0000\n","Epoch 148/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4538844108.5326 - val_loss: 6675088384.0000\n","Epoch 149/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4334632371.1332 - val_loss: 6692020224.0000\n","Epoch 150/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4278822077.1593 - val_loss: 6656613888.0000\n","Epoch 151/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4388913418.0261 - val_loss: 6722884096.0000\n","Epoch 152/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4443008088.2298 - val_loss: 6644272128.0000\n","Epoch 153/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4329493910.0574 - val_loss: 6658475520.0000\n","Epoch 154/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4258507753.2742 - val_loss: 6583642112.0000\n","Epoch 155/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4453774888.7728 - val_loss: 6425277952.0000\n","Epoch 156/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4450399180.8668 - val_loss: 6537634304.0000\n","Epoch 157/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4389140065.9217 - val_loss: 6764027392.0000\n","Epoch 158/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4496161086.1619 - val_loss: 6621756416.0000\n","Epoch 159/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4365869013.5561 - val_loss: 6534134272.0000\n","Epoch 160/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4351417451.6136 - val_loss: 6499718656.0000\n","Epoch 161/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4345553272.3133 - val_loss: 6575819264.0000\n","Epoch 162/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4261054201.6501 - val_loss: 6374390784.0000\n","Epoch 163/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4180012036.3446 - val_loss: 6635338240.0000\n","Epoch 164/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4287462783.6658 - val_loss: 6538491904.0000\n","Epoch 165/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4376210087.9373 - val_loss: 6602725888.0000\n","Epoch 166/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4493605495.6449 - val_loss: 6550850048.0000\n","Epoch 167/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4248997156.0940 - val_loss: 6504093696.0000\n","Epoch 168/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4491609737.0235 - val_loss: 6466139648.0000\n","Epoch 169/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4355181998.4543 - val_loss: 6691559936.0000\n","Epoch 170/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4153375398.7676 - val_loss: 6353979904.0000\n","Epoch 171/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4438819512.1462 - val_loss: 6680631296.0000\n","Epoch 172/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4318617890.7572 - val_loss: 6503520768.0000\n","Epoch 173/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4330691266.8407 - val_loss: 6496184320.0000\n","Epoch 174/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4337084127.9164 - val_loss: 6490449920.0000\n","Epoch 175/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4367247208.6057 - val_loss: 6401765376.0000\n","Epoch 176/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4198888767.8329 - val_loss: 6606916608.0000\n","Epoch 177/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4274407216.7937 - val_loss: 6508369408.0000\n","Epoch 178/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4283400975.3734 - val_loss: 6577674240.0000\n","Epoch 179/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4280761492.3864 - val_loss: 6380672000.0000\n","Epoch 180/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4267747263.1645 - val_loss: 6308348416.0000\n","Epoch 181/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4263406113.4204 - val_loss: 6431520256.0000\n","Epoch 182/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4289912131.8433 - val_loss: 6391851008.0000\n","Epoch 183/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4224985117.7441 - val_loss: 6323662848.0000\n","Epoch 184/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4304172018.4648 - val_loss: 6416308224.0000\n","Epoch 185/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4210232730.0679 - val_loss: 6331767808.0000\n","Epoch 186/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4208543773.4099 - val_loss: 6291919872.0000\n","Epoch 187/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4275736598.2245 - val_loss: 6299983360.0000\n","Epoch 188/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4219935735.9791 - val_loss: 6283670016.0000\n","Epoch 189/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4196699097.2324 - val_loss: 6418948608.0000\n","Epoch 190/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4291831072.0836 - val_loss: 6361216512.0000\n","Epoch 191/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4353283897.1488 - val_loss: 6409331200.0000\n","Epoch 192/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4268720017.7128 - val_loss: 6153462272.0000\n","Epoch 193/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4192334942.9138 - val_loss: 6219603456.0000\n","Epoch 194/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4363673818.4021 - val_loss: 6454412288.0000\n","Epoch 195/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4216989059.0078 - val_loss: 6127282688.0000\n","Epoch 196/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4400707774.4961 - val_loss: 6322727424.0000\n","Epoch 197/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4256934257.6292 - val_loss: 6191130112.0000\n","Epoch 198/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4266684230.1828 - val_loss: 6259217920.0000\n","Epoch 199/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4276890423.4778 - val_loss: 6336988672.0000\n","Epoch 200/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4274023044.0104 - val_loss: 6376362496.0000\n","Epoch 201/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4188501357.9530 - val_loss: 6219647488.0000\n","Epoch 202/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4375341251.1749 - val_loss: 6341654528.0000\n","Epoch 203/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4103719710.0783 - val_loss: 6268532736.0000\n","Epoch 204/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4346341623.6449 - val_loss: 6104799744.0000\n","Epoch 205/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4272225196.4491 - val_loss: 6252167168.0000\n","Epoch 206/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4372783603.6345 - val_loss: 6201827328.0000\n","Epoch 207/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4277671404.2820 - val_loss: 6191920640.0000\n","Epoch 208/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4269473502.4125 - val_loss: 6405862400.0000\n","Epoch 209/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4360845278.9138 - val_loss: 6263424000.0000\n","Epoch 210/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4220648913.2115 - val_loss: 6111866368.0000\n","Epoch 211/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4222734695.2689 - val_loss: 6242164224.0000\n","Epoch 212/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4211487603.3003 - val_loss: 6187415040.0000\n","Epoch 213/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4211008802.7572 - val_loss: 6377006080.0000\n","Epoch 214/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4309282046.9974 - val_loss: 6174682112.0000\n","Epoch 215/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4189047019.9478 - val_loss: 6330102272.0000\n","Epoch 216/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4098115744.4178 - val_loss: 6183567872.0000\n","Epoch 217/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4257082505.5248 - val_loss: 6166464512.0000\n","Epoch 218/1000\n","765/765 [==============================] - 1s 1ms/step - loss: 4231529508.7624 - val_loss: 6222725632.0000\n","Epoch 219/1000\n","765/765 [==============================] - 1s 2ms/step - loss: 4309023509.8903 - val_loss: 6181966848.0000\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a0fccd36b95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m           callbacks=[early_stopping])\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1613\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3000\n  y sizes: 17000\nMake sure all arrays contain the same number of samples."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxMIgm2rSHUt","executionInfo":{"status":"ok","timestamp":1626287423795,"user_tz":240,"elapsed":2,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"0a437749-3902-4b91-c0ba-0796a1b69585"},"source":["y_test.describe()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count     17000.000000\n","mean     207300.912353\n","std      115983.764387\n","min       14999.000000\n","25%      119400.000000\n","50%      180400.000000\n","75%      265000.000000\n","max      500001.000000\n","Name: median_house_value, dtype: float64"]},"metadata":{"tags":[]},"execution_count":12}]}]}