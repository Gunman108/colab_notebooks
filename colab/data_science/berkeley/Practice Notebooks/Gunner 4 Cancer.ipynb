{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gunner 4 Cancer.ipynb","provenance":[{"file_id":"1ao0Tp30ZpN2ViiZZmRi8TjC4q_B_i_Y2","timestamp":1626289048826},{"file_id":"1IUWnilzeKlpeWq8e1L8Wu9098rpMAtip","timestamp":1626288988238},{"file_id":"1JoT9215ZPq0bQ5mqURDHGXh9yNcMk4Pm","timestamp":1626115923349}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bUn8nP219d1V"},"source":["1. Load the Abalone Shells dataset from the pervious notebook and find the RMSE. Try out some different regressors. What gives the best score? Share your score in the chat and let people know what model and if you made any adjustments."]},{"cell_type":"code","metadata":{"id":"dD0uNP3R9bgz","executionInfo":{"status":"ok","timestamp":1626289681700,"user_tz":240,"elapsed":87,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["import pandas as pd\n"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5sQiRu6R9rsf"},"source":["2. Open the following Breast Cancer UCI Machine Learning Repository url in pandas. To access the columns, go to the [data source:](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)"]},{"cell_type":"markdown","metadata":{"id":"HkZSWFXs-oyP"},"source":["Refer back to your previous notebook if you need support setting up the columns."]},{"cell_type":"code","metadata":{"id":"7C5rs9m_-RAQ","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1626289682388,"user_tz":240,"elapsed":604,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"4f8db242-6453-4a5d-9925-8744d2a28cb9"},"source":["url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n","df = pd.read_csv(url)\n","df.columns = ['ID', 'Diagnosis', 'radius','texture','perimeter', 'area','smoothness','compactness','concavity','cp','symmetry','fd', 'radius','texture','perimeter', 'area','smoothness','compactness','concavity','cp','symmetry','fd', 'radius','texture','perimeter', 'area','smoothness','compactness','concavity','cp','symmetry','fd']\n","df.head()"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Diagnosis</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>843786</td>\n","      <td>M</td>\n","      <td>12.45</td>\n","      <td>15.70</td>\n","      <td>82.57</td>\n","      <td>477.1</td>\n","      <td>0.12780</td>\n","      <td>0.17000</td>\n","      <td>0.1578</td>\n","      <td>0.08089</td>\n","      <td>0.2087</td>\n","      <td>0.07613</td>\n","      <td>0.3345</td>\n","      <td>0.8902</td>\n","      <td>2.217</td>\n","      <td>27.19</td>\n","      <td>0.007510</td>\n","      <td>0.03345</td>\n","      <td>0.03672</td>\n","      <td>0.01137</td>\n","      <td>0.02165</td>\n","      <td>0.005082</td>\n","      <td>15.47</td>\n","      <td>23.75</td>\n","      <td>103.40</td>\n","      <td>741.6</td>\n","      <td>0.1791</td>\n","      <td>0.5249</td>\n","      <td>0.5355</td>\n","      <td>0.1741</td>\n","      <td>0.3985</td>\n","      <td>0.12440</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         ID Diagnosis  radius  texture  ...  concavity      cp  symmetry       fd\n","0    842517         M   20.57    17.77  ...     0.2416  0.1860    0.2750  0.08902\n","1  84300903         M   19.69    21.25  ...     0.4504  0.2430    0.3613  0.08758\n","2  84348301         M   11.42    20.38  ...     0.6869  0.2575    0.6638  0.17300\n","3  84358402         M   20.29    14.34  ...     0.4000  0.1625    0.2364  0.07678\n","4    843786         M   12.45    15.70  ...     0.5355  0.1741    0.3985  0.12440\n","\n","[5 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"JWlRi3QaBfYH"},"source":["3. To set up X, and y, you need to convert the target column from M and B to 0 and 1. Try the following code, replacing 'col_name' with the name of your columns. Then verify the changes.\n"]},{"cell_type":"code","metadata":{"id":"PXWlsbI6ByVw","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1626289682389,"user_tz":240,"elapsed":4,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"148e9748-64c1-44b3-a927-e5c29d04d9e7"},"source":["df['Diagnosis'] = pd.factorize(df['Diagnosis'])[0]\n","df.head()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Diagnosis</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","      <th>radius</th>\n","      <th>texture</th>\n","      <th>perimeter</th>\n","      <th>area</th>\n","      <th>smoothness</th>\n","      <th>compactness</th>\n","      <th>concavity</th>\n","      <th>cp</th>\n","      <th>symmetry</th>\n","      <th>fd</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842517</td>\n","      <td>0</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>84300903</td>\n","      <td>0</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84348301</td>\n","      <td>0</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84358402</td>\n","      <td>0</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>843786</td>\n","      <td>0</td>\n","      <td>12.45</td>\n","      <td>15.70</td>\n","      <td>82.57</td>\n","      <td>477.1</td>\n","      <td>0.12780</td>\n","      <td>0.17000</td>\n","      <td>0.1578</td>\n","      <td>0.08089</td>\n","      <td>0.2087</td>\n","      <td>0.07613</td>\n","      <td>0.3345</td>\n","      <td>0.8902</td>\n","      <td>2.217</td>\n","      <td>27.19</td>\n","      <td>0.007510</td>\n","      <td>0.03345</td>\n","      <td>0.03672</td>\n","      <td>0.01137</td>\n","      <td>0.02165</td>\n","      <td>0.005082</td>\n","      <td>15.47</td>\n","      <td>23.75</td>\n","      <td>103.40</td>\n","      <td>741.6</td>\n","      <td>0.1791</td>\n","      <td>0.5249</td>\n","      <td>0.5355</td>\n","      <td>0.1741</td>\n","      <td>0.3985</td>\n","      <td>0.12440</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         ID  Diagnosis  radius  texture  ...  concavity      cp  symmetry       fd\n","0    842517          0   20.57    17.77  ...     0.2416  0.1860    0.2750  0.08902\n","1  84300903          0   19.69    21.25  ...     0.4504  0.2430    0.3613  0.08758\n","2  84348301          0   11.42    20.38  ...     0.6869  0.2575    0.6638  0.17300\n","3  84358402          0   20.29    14.34  ...     0.4000  0.1625    0.2364  0.07678\n","4    843786          0   12.45    15.70  ...     0.5355  0.1741    0.3985  0.12440\n","\n","[5 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"HefmmgX7-yiI"},"source":["4. Train a model using multiple classifiers as shown during lecture. Try to predict whether the cancer is malignant or benign. Which model gives the best results?"]},{"cell_type":"code","metadata":{"id":"WTd5zNre-6TM","executionInfo":{"status":"ok","timestamp":1626289682498,"user_tz":240,"elapsed":112,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["from sklearn.model_selection import train_test_split\n","y = df[\"Diagnosis\"]\n","X = df.drop(\"Diagnosis\",axis = 1,inplace=False)\n","\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JkTfymTYxSo","executionInfo":{"status":"ok","timestamp":1626289682499,"user_tz":240,"elapsed":3,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TJlOTAOYzDb","executionInfo":{"status":"ok","timestamp":1626289703604,"user_tz":240,"elapsed":10879,"user":{"displayName":"Gunner Peterson","photoUrl":"","userId":"02754107879288077326"}},"outputId":"997e027b-070e-4ade-ce30-17e1425dfca3"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.callbacks import EarlyStopping\n","\n","num_cols = X_train.shape[1]\n","\n","#init model\n","model = Sequential()\n","\n","model.add(Dense(8, input_shape=(num_cols,),activation='relu'))\n","\n","\n","model.add(Dense(80, activation='relu'))\n","model.add(Dropout(.2))\n","model.add(Dense(70, activation='relu'))\n","model.add(Dense(60, activation='relu'))\n","model.add(Dropout(.2))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","print(model.summary())\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n","\n","early_stopping = EarlyStopping(patience=30)\n","\n","model.fit(X_train, y_train, epochs=1000, batch_size=20, validation_split=0.1,\n","          callbacks=[early_stopping])\n","\n","model.evaluate(X_test, y_test)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Model: \"sequential_18\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_89 (Dense)             (None, 8)                 256       \n","_________________________________________________________________\n","dense_90 (Dense)             (None, 80)                720       \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 80)                0         \n","_________________________________________________________________\n","dense_91 (Dense)             (None, 70)                5670      \n","_________________________________________________________________\n","dense_92 (Dense)             (None, 60)                4260      \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 60)                0         \n","_________________________________________________________________\n","dense_93 (Dense)             (None, 1)                 61        \n","=================================================================\n","Total params: 10,967\n","Trainable params: 10,967\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/1000\n","21/21 [==============================] - 1s 22ms/step - loss: 0.6871 - accuracy: 0.6173 - val_loss: 0.6445 - val_accuracy: 0.7174\n","Epoch 2/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.7268 - val_loss: 0.5092 - val_accuracy: 0.8043\n","Epoch 3/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8682 - val_loss: 0.3379 - val_accuracy: 0.8696\n","Epoch 4/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9211 - val_loss: 0.2744 - val_accuracy: 0.8478\n","Epoch 5/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9180 - val_loss: 0.2405 - val_accuracy: 0.8696\n","Epoch 6/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9449 - val_loss: 0.2203 - val_accuracy: 0.8913\n","Epoch 7/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9450 - val_loss: 0.1850 - val_accuracy: 0.8913\n","Epoch 8/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9607 - val_loss: 0.1837 - val_accuracy: 0.8913\n","Epoch 9/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 0.1604 - val_accuracy: 0.9130\n","Epoch 10/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9456 - val_loss: 0.1316 - val_accuracy: 0.9348\n","Epoch 11/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9435 - val_loss: 0.1351 - val_accuracy: 0.9348\n","Epoch 12/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9282 - val_loss: 0.0970 - val_accuracy: 0.9348\n","Epoch 13/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9480 - val_loss: 0.0854 - val_accuracy: 0.9783\n","Epoch 14/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9546 - val_loss: 0.1365 - val_accuracy: 0.9348\n","Epoch 15/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9661 - val_loss: 0.0761 - val_accuracy: 0.9783\n","Epoch 16/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9781 - val_loss: 0.0681 - val_accuracy: 0.9783\n","Epoch 17/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9829 - val_loss: 0.0574 - val_accuracy: 1.0000\n","Epoch 18/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9618 - val_loss: 0.0544 - val_accuracy: 1.0000\n","Epoch 19/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9773 - val_loss: 0.0467 - val_accuracy: 1.0000\n","Epoch 20/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 0.0380 - val_accuracy: 1.0000\n","Epoch 21/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9855 - val_loss: 0.0499 - val_accuracy: 1.0000\n","Epoch 22/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9784 - val_loss: 0.0300 - val_accuracy: 1.0000\n","Epoch 23/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9635 - val_loss: 0.0310 - val_accuracy: 1.0000\n","Epoch 24/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9772 - val_loss: 0.0291 - val_accuracy: 1.0000\n","Epoch 25/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9759 - val_loss: 0.0466 - val_accuracy: 0.9783\n","Epoch 26/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9679 - val_loss: 0.0762 - val_accuracy: 0.9565\n","Epoch 27/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9795 - val_loss: 0.0461 - val_accuracy: 0.9783\n","Epoch 28/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9790 - val_loss: 0.0387 - val_accuracy: 0.9783\n","Epoch 29/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9677 - val_loss: 0.0241 - val_accuracy: 1.0000\n","Epoch 30/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9758 - val_loss: 0.0249 - val_accuracy: 1.0000\n","Epoch 31/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.0178 - val_accuracy: 1.0000\n","Epoch 32/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0274 - val_accuracy: 0.9783\n","Epoch 33/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0176 - val_accuracy: 1.0000\n","Epoch 34/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9648 - val_loss: 0.0221 - val_accuracy: 1.0000\n","Epoch 35/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9762 - val_loss: 0.0308 - val_accuracy: 0.9783\n","Epoch 36/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9909 - val_loss: 0.0467 - val_accuracy: 0.9783\n","Epoch 37/1000\n","21/21 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9766 - val_loss: 0.0383 - val_accuracy: 0.9783\n","Epoch 38/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 0.0471 - val_accuracy: 0.9783\n","Epoch 39/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9798 - val_loss: 0.0611 - val_accuracy: 0.9783\n","Epoch 40/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9820 - val_loss: 0.0142 - val_accuracy: 1.0000\n","Epoch 41/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9918 - val_loss: 0.0124 - val_accuracy: 1.0000\n","Epoch 42/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9847 - val_loss: 0.0217 - val_accuracy: 0.9783\n","Epoch 43/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9968 - val_loss: 0.0683 - val_accuracy: 0.9783\n","Epoch 44/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9860 - val_loss: 0.0508 - val_accuracy: 0.9783\n","Epoch 45/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9828 - val_loss: 0.0203 - val_accuracy: 1.0000\n","Epoch 46/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9804 - val_loss: 0.0146 - val_accuracy: 1.0000\n","Epoch 47/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9837 - val_loss: 0.0202 - val_accuracy: 1.0000\n","Epoch 48/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9927 - val_loss: 0.0133 - val_accuracy: 1.0000\n","Epoch 49/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9955 - val_loss: 0.0418 - val_accuracy: 0.9783\n","Epoch 50/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.0122 - val_accuracy: 1.0000\n","Epoch 51/1000\n","21/21 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.0434 - val_accuracy: 0.9783\n","Epoch 52/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9873 - val_loss: 0.1351 - val_accuracy: 0.9565\n","Epoch 53/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9986 - val_loss: 0.0258 - val_accuracy: 0.9783\n","Epoch 54/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0923 - val_accuracy: 0.9565\n","Epoch 55/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9705 - val_loss: 0.0402 - val_accuracy: 0.9783\n","Epoch 56/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9920 - val_loss: 0.0172 - val_accuracy: 1.0000\n","Epoch 57/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9804 - val_loss: 0.0579 - val_accuracy: 0.9783\n","Epoch 58/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.0113 - val_accuracy: 1.0000\n","Epoch 59/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.0547 - val_accuracy: 0.9783\n","Epoch 60/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9823 - val_loss: 0.0825 - val_accuracy: 0.9565\n","Epoch 61/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.0440 - val_accuracy: 0.9783\n","Epoch 62/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9919 - val_loss: 0.0280 - val_accuracy: 0.9783\n","Epoch 63/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0162 - val_accuracy: 1.0000\n","Epoch 64/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0341 - val_accuracy: 0.9783\n","Epoch 65/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.0625 - val_accuracy: 0.9783\n","Epoch 66/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 0.0683 - val_accuracy: 0.9565\n","Epoch 67/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9883 - val_loss: 0.0200 - val_accuracy: 1.0000\n","Epoch 68/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9902 - val_loss: 0.3425 - val_accuracy: 0.9348\n","Epoch 69/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9706 - val_loss: 0.0209 - val_accuracy: 1.0000\n","Epoch 70/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9861 - val_loss: 0.0548 - val_accuracy: 0.9565\n","Epoch 71/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0115 - val_accuracy: 1.0000\n","Epoch 72/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0439 - val_accuracy: 0.9565\n","Epoch 73/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9994 - val_loss: 0.0515 - val_accuracy: 0.9565\n","Epoch 74/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9947 - val_loss: 0.0390 - val_accuracy: 0.9565\n","Epoch 75/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.0078 - val_accuracy: 1.0000\n","Epoch 76/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9803 - val_loss: 0.0069 - val_accuracy: 1.0000\n","Epoch 77/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9978 - val_loss: 0.0354 - val_accuracy: 0.9783\n","Epoch 78/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.0502 - val_accuracy: 0.9783\n","Epoch 79/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 0.0187 - val_accuracy: 1.0000\n","Epoch 80/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0285 - val_accuracy: 0.9783\n","Epoch 81/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0301 - val_accuracy: 0.9783\n","Epoch 82/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9918 - val_loss: 0.0884 - val_accuracy: 0.9565\n","Epoch 83/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0391 - val_accuracy: 0.9565\n","Epoch 84/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1595 - val_accuracy: 0.9565\n","Epoch 85/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.1326 - val_accuracy: 0.9565\n","Epoch 86/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.0873 - val_accuracy: 0.9565\n","Epoch 87/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.1577 - val_accuracy: 0.9565\n","Epoch 88/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1728 - val_accuracy: 0.9565\n","Epoch 89/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 1.0000\n","Epoch 90/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9899 - val_loss: 0.1945 - val_accuracy: 0.9565\n","Epoch 91/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9943 - val_loss: 0.1418 - val_accuracy: 0.9565\n","Epoch 92/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0888 - val_accuracy: 0.9565\n","Epoch 93/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0518 - val_accuracy: 0.9783\n","Epoch 94/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 95/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0469 - val_accuracy: 0.9783\n","Epoch 96/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9901 - val_loss: 0.3228 - val_accuracy: 0.9565\n","Epoch 97/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9842 - val_loss: 0.1894 - val_accuracy: 0.9565\n","Epoch 98/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.1303 - val_accuracy: 0.9565\n","Epoch 99/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9919 - val_loss: 0.0862 - val_accuracy: 0.9565\n","Epoch 100/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9888 - val_loss: 0.0065 - val_accuracy: 1.0000\n","Epoch 101/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9892 - val_loss: 0.1003 - val_accuracy: 0.9565\n","Epoch 102/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.2082 - val_accuracy: 0.9565\n","Epoch 103/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9940 - val_loss: 0.1151 - val_accuracy: 0.9565\n","Epoch 104/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0433 - val_accuracy: 0.9565\n","Epoch 105/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9565\n","Epoch 106/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9963 - val_loss: 0.1945 - val_accuracy: 0.9565\n","Epoch 107/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9783\n","Epoch 108/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1040 - val_accuracy: 0.9565\n","Epoch 109/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.2342 - val_accuracy: 0.9565\n","Epoch 110/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n","Epoch 111/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.2737 - val_accuracy: 0.9565\n","Epoch 112/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9565\n","Epoch 113/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.2819 - val_accuracy: 0.9565\n","Epoch 114/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0518 - val_accuracy: 0.9783\n","Epoch 115/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0828 - val_accuracy: 0.9565\n","Epoch 116/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9565\n","Epoch 117/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9978 - val_loss: 0.2218 - val_accuracy: 0.9565\n","Epoch 118/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.1175 - val_accuracy: 0.9565\n","Epoch 119/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9930 - val_loss: 0.0895 - val_accuracy: 0.9565\n","Epoch 120/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0979 - val_accuracy: 0.9565\n","Epoch 121/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9565\n","Epoch 122/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1327 - val_accuracy: 0.9565\n","Epoch 123/1000\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9916 - val_loss: 0.1384 - val_accuracy: 0.9565\n","Epoch 124/1000\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9565\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.9561\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3744823932647705, 0.9561403393745422]"]},"metadata":{"tags":[]},"execution_count":35}]}]}