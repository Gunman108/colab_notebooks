{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP WYR Method Testing","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhF7rKaBXR5Q0xPNtn5sek"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"mQu3u8McdpEt"},"source":["import pandas as pd\n","import numpy as np\n","import sklearn\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yvQUbbw8hCNd"},"source":["phrases = [ \"The quick brown fox jumped over the lazy dog\",\n","           \"This is the second sentence we shall test\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWFohqGThYKG","executionInfo":{"status":"ok","timestamp":1645729924389,"user_tz":300,"elapsed":187,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"ed259cc6-d4f3-41b4-f031-46cb65e4c9a6"},"source":["vect = CountVectorizer()\n","vect.fit(phrases)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer()"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"em7aM3CyhboN","executionInfo":{"status":"ok","timestamp":1645729925342,"user_tz":300,"elapsed":182,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"df65271d-2626-4d11-e848-2952a862e7c3"},"source":["print(\"Vocabulary Size: {}\".format(len(vect.vocabulary_)))\n","print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Size: 15\n","Vocabulary content:\n"," {'the': 12, 'quick': 7, 'brown': 0, 'fox': 2, 'jumped': 4, 'over': 6, 'lazy': 5, 'dog': 1, 'this': 13, 'is': 3, 'second': 8, 'sentence': 9, 'we': 14, 'shall': 10, 'test': 11}\n"]}]},{"cell_type":"code","metadata":{"id":"kKkUwfon7amZ"},"source":["bag_of_words = vect.transform(phrases)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtXowAVf7fP9","executionInfo":{"status":"ok","timestamp":1645729926970,"user_tz":300,"elapsed":4,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"5f601058-922f-40f3-efda-3dbe8da503a8"},"source":["print(bag_of_words)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (0, 0)\t1\n","  (0, 1)\t1\n","  (0, 2)\t1\n","  (0, 4)\t1\n","  (0, 5)\t1\n","  (0, 6)\t1\n","  (0, 7)\t1\n","  (0, 12)\t2\n","  (1, 3)\t1\n","  (1, 8)\t1\n","  (1, 9)\t1\n","  (1, 10)\t1\n","  (1, 11)\t1\n","  (1, 12)\t1\n","  (1, 13)\t1\n","  (1, 14)\t1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8tE2UdK7o6L","executionInfo":{"status":"ok","timestamp":1645729928172,"user_tz":300,"elapsed":3,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"40a51bda-c762-459a-9bde-fba263395c88"},"source":["print(\"bag of words as an array:\\n{}\".format(bag_of_words.toarray()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bag of words as an array:\n","[[1 1 1 0 1 1 1 1 0 0 0 0 2 0 0]\n"," [0 0 0 1 0 0 0 0 1 1 1 1 1 1 1]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htPDJwxP8J9F","executionInfo":{"status":"ok","timestamp":1645729929184,"user_tz":300,"elapsed":182,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"8452c4ea-81bb-49d2-d29e-c858a7e2abe9"},"source":["vect.get_feature_names()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["['brown',\n"," 'dog',\n"," 'fox',\n"," 'is',\n"," 'jumped',\n"," 'lazy',\n"," 'over',\n"," 'quick',\n"," 'second',\n"," 'sentence',\n"," 'shall',\n"," 'test',\n"," 'the',\n"," 'this',\n"," 'we']"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["##Data Processing/Bag of Words"],"metadata":{"id":"OEjjXd_01IsN"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7SbQOweJkW1","executionInfo":{"status":"ok","timestamp":1645729972531,"user_tz":300,"elapsed":13666,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"65daba52-1e9d-498f-efb9-e02b4d9cd32f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"VC2ZoMBc8Oe7"},"source":["data_directory = '/content/drive/MyDrive/CS/Datasets/wyr_seperated.csv'\n","data = pd.read_csv(data_directory)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3WKhnfpr7gD","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1645730020395,"user_tz":300,"elapsed":174,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"71fe4454-6378-46d2-8c83-2de988ba5c2c"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-b1144a96-50d2-4f4c-97c9-5f836c7c1c92\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>percent</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Run 26 miles</td>\n","      <td>50</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Swim 5 miles</td>\n","      <td>50</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Your partner have a homosexual affair</td>\n","      <td>59</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Your partner have a heterosexual affair</td>\n","      <td>41</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Have a Pepsi</td>\n","      <td>35</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1144a96-50d2-4f4c-97c9-5f836c7c1c92')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b1144a96-50d2-4f4c-97c9-5f836c7c1c92 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b1144a96-50d2-4f4c-97c9-5f836c7c1c92');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                   question  percent  id\n","0                             Run 26 miles        50   3\n","1                             Swim 5 miles        50   3\n","2    Your partner have a homosexual affair        59   4\n","3  Your partner have a heterosexual affair        41   4\n","4                             Have a Pepsi        35   5"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["result = []\n","\n","data = data[data.percent > 0]\n","data = data[data.percent < 100]\n","percentcol = data[\"percent\"]\n","\n","percent_list = percentcol.tolist()\n","\n","for i in percent_list:\n","  if i <=50:\n","    result.append(0)\n","  else:\n","    result.append(1)\n","\n","print(result)\n","\n","data[\"result\"] = result\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"DlvkrTdoJ8YQ","executionInfo":{"status":"ok","timestamp":1645730092679,"user_tz":300,"elapsed":144,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"66c8d3c5-d5ed-4fd4-f928-709ef895833b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3d1b7205-9705-4b22-8758-8d20aab80c5e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>percent</th>\n","      <th>id</th>\n","      <th>result</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Run 26 miles</td>\n","      <td>50</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Swim 5 miles</td>\n","      <td>50</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Your partner have a homosexual affair</td>\n","      <td>59</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Your partner have a heterosexual affair</td>\n","      <td>41</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Have a Pepsi</td>\n","      <td>35</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d1b7205-9705-4b22-8758-8d20aab80c5e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3d1b7205-9705-4b22-8758-8d20aab80c5e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3d1b7205-9705-4b22-8758-8d20aab80c5e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                   question  percent  id  result\n","0                             Run 26 miles        50   3       0\n","1                             Swim 5 miles        50   3       0\n","2    Your partner have a homosexual affair        59   4       1\n","3  Your partner have a heterosexual affair        41   4       0\n","4                             Have a Pepsi        35   5       0"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlz7PSo7PrCY","executionInfo":{"status":"ok","timestamp":1645730099809,"user_tz":300,"elapsed":170,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"0a477c83-87d0-4d1f-a031-b76a92f41470"},"source":["print(\"Samples per class: {}\".format(np.bincount(data.result)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Samples per class: [1001  961]\n"]}]},{"cell_type":"code","metadata":{"id":"1g_tvR7CPyd-"},"source":["def simple_split(data,y,length,split_mark=0.7):\n","  if split_mark > 0. and split_mark < 1.0:\n","    n = int(split_mark*length)\n","  else:\n","    n = int(split_mark)\n","  X_train = data[:n].copy()\n","  X_test = data[n:].copy()\n","  y_train = y[:n].copy()\n","  y_test = y[n:].copy()\n","  return X_train,X_test, y_train, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiNl2inzQgmk"},"source":["vectorizer = CountVectorizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEZvlvTSQm0Z","executionInfo":{"status":"ok","timestamp":1645730116494,"user_tz":300,"elapsed":143,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"b77882e8-3d45-4a15-ccaf-034f3bddb329"},"source":["X_train, X_test, y_train, y_test = simple_split(data.question, data.result, len(data))\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1373,) (589,) (1373,) (589,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5gnWIjGQ5bf","executionInfo":{"status":"ok","timestamp":1645730118582,"user_tz":300,"elapsed":3,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"6235b5d3-8694-432b-8405-e8600f510cd1"},"source":["print(\"Samples per class: {}\".format(np.bincount(y_train)))\n","print(\"Samples per class: {}\".format(np.bincount(y_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Samples per class: [702 671]\n","Samples per class: [299 290]\n"]}]},{"cell_type":"code","metadata":{"id":"ZXSl-3e5RExD"},"source":["X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAeZ-oCnRQ0K","executionInfo":{"status":"ok","timestamp":1645730124434,"user_tz":300,"elapsed":136,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"344e5773-661e-47a8-c001-3d8824baf94f"},"source":["feature_names = vectorizer.get_feature_names()\n","print(\"Number of features: {}\".format(len(feature_names)))\n","print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n","print(\"Features 19500 to 19530:\\n{}\".format(feature_names[19500:19530]))\n","print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of features: 2144\n","First 20 features:\n","['000', '10', '100', '12', '1337', '13th', '15', '150', '16', '18', '1989', '1st', '20', '200', '2008', '24', '25', '250', '26', '30']\n","Features 19500 to 19530:\n","[]\n","Every 2000th feature:\n","['000', 'vacation']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qStEaVQMR91d","executionInfo":{"status":"ok","timestamp":1645730127420,"user_tz":300,"elapsed":162,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"4a72629b-af06-4b2a-be0b-ab0cb808301b"},"source":["vectorizer.vocabulary_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'run': 1582,\n"," '26': 18,\n"," 'miles': 1190,\n"," 'swim': 1834,\n"," 'your': 2137,\n"," 'partner': 1374,\n"," 'have': 832,\n"," 'homosexual': 874,\n"," 'affair': 61,\n"," 'heterosexual': 850,\n"," 'pepsi': 1396,\n"," 'coke': 393,\n"," 'watch': 2048,\n"," 'only': 1327,\n"," 'dramas': 543,\n"," 'for': 703,\n"," 'the': 1892,\n"," 'rest': 1543,\n"," 'of': 1316,\n"," 'life': 1073,\n"," 'comedies': 401,\n"," 'burn': 274,\n"," 'to': 1916,\n"," 'death': 485,\n"," 'drown': 552,\n"," 'favorite': 659,\n"," 'movie': 1231,\n"," 'on': 1322,\n"," 'repeat': 1534,\n"," 'full': 730,\n"," 'day': 479,\n"," 'nick': 1279,\n"," 'and': 92,\n"," 'norah': 1297,\n"," 'infinite': 921,\n"," 'playlist': 1430,\n"," 'once': 1323,\n"," 'live': 1094,\n"," 'until': 1990,\n"," '80': 33,\n"," 'in': 912,\n"," 'poverty': 1457,\n"," '40': 21,\n"," 'riches': 1553,\n"," 'be': 172,\n"," 'stabbed': 1759,\n"," 'stomach': 1785,\n"," '10': 1,\n"," 'times': 1913,\n"," 'shot': 1652,\n"," 'both': 246,\n"," 'kneecaps': 1019,\n"," 'wilma': 2091,\n"," 'flintstone': 690,\n"," 'velma': 2011,\n"," 'from': 725,\n"," 'scooby': 1611,\n"," 'doo': 533,\n"," 'mystery': 1247,\n"," 'gang': 738,\n"," 'no': 1290,\n"," 'tongue': 1924,\n"," 'teeth': 1869,\n"," 'john': 984,\n"," 'lennon': 1061,\n"," 'paul': 1380,\n"," 'mccartney': 1162,\n"," 'famous': 652,\n"," 'this': 1903,\n"," 'lifetime': 1075,\n"," 'go': 762,\n"," 'down': 538,\n"," 'history': 857,\n"," 'books': 243,\n"," 'topless': 1928,\n"," 'all': 76,\n"," 'time': 1912,\n"," 'pantless': 1363,\n"," 'lose': 1110,\n"," 'preferred': 1461,\n"," 'hand': 815,\n"," 'foot': 701,\n"," 'dance': 472,\n"," 'like': 1078,\n"," 'michael': 1185,\n"," 'jackson': 959,\n"," 'sing': 1670,\n"," 'freddie': 714,\n"," 'mercury': 1179,\n"," 'ache': 50,\n"," 'headache': 835,\n"," 'give': 758,\n"," 'speech': 1742,\n"," 'whole': 2083,\n"," 'nation': 1259,\n"," 'sleep': 1694,\n"," 'with': 2097,\n"," 'tarantulas': 1859,\n"," 'bed': 182,\n"," 'centaur': 324,\n"," 'mermaid': 1180,\n"," 'man': 1137,\n"," 'child': 356,\n"," '7th': 32,\n"," 'grade': 776,\n"," 'raise': 1508,\n"," 'it': 951,\n"," 'never': 1272,\n"," 'kids': 1008,\n"," 'adopt': 59,\n"," 'hours': 889,\n"," 'everyday': 622,\n"," '15': 6,\n"," 'snort': 1716,\n"," 'one': 1324,\n"," 'crushed': 457,\n"," 'up': 1991,\n"," 'altoid': 83,\n"," 'mint': 1198,\n"," 'spearmint': 1741,\n"," 'take': 1851,\n"," 'oz': 1352,\n"," 'tabasco': 1843,\n"," 'sauce': 1602,\n"," 'cat': 314,\n"," 'dog': 527,\n"," 'deaf': 483,\n"," 'legs': 1059,\n"," 'blind': 221,\n"," 'arms': 119,\n"," 'jail': 960,\n"," 'year': 2130,\n"," 'complete': 413,\n"," 'isolation': 950,\n"," 'mountains': 1227,\n"," 'string': 1796,\n"," 'opponent': 1331,\n"," 'along': 82,\n"," 'entire': 610,\n"," 'fight': 669,\n"," 'crush': 456,\n"," 'them': 1894,\n"," 'beginning': 190,\n"," 'speak': 1738,\n"," 'every': 620,\n"," 'language': 1036,\n"," 'except': 630,\n"," 'country': 439,\n"," 'you': 2135,\n"," 're': 1515,\n"," 'currently': 463,\n"," 'but': 283,\n"," 'know': 1026,\n"," 'meaning': 1167,\n"," 'single': 1672,\n"," 'word': 2109,\n"," 'that': 1890,\n"," 'hands': 818,\n"," 'switched': 1838,\n"," 'dustpans': 563,\n"," 'sweating': 1832,\n"," 'jam': 961,\n"," 'instead': 930,\n"," 'sweat': 1831,\n"," 'naked': 1251,\n"," 'fat': 657,\n"," 'guy': 807,\n"," 'stalking': 1766,\n"," 'at': 130,\n"," 'chev': 354,\n"," 'chelios': 353,\n"," 'crank': 446,\n"," 'transporter': 1938,\n"," 'jackie': 957,\n"," 'chan': 333,\n"," 'jet': 976,\n"," 'li': 1068,\n"," 'batman': 170,\n"," 'superman': 1821,\n"," 'telekinetic': 1870,\n"," 'telepathic': 1871,\n"," 'always': 84,\n"," 'hot': 886,\n"," 'cold': 394,\n"," 'horribly': 881,\n"," 'hopelessly': 877,\n"," 'depressed': 492,\n"," 'inescapable': 918,\n"," 'overwhelming': 1349,\n"," 'anxiety': 104,\n"," 'become': 181,\n"," 'superhero': 1819,\n"," 'supervillian': 1823,\n"," 'hung': 896,\n"," 'by': 287,\n"," 'noose': 1296,\n"," 'decapitated': 486,\n"," 'guillotine': 799,\n"," 'two': 1966,\n"," 'sets': 1631,\n"," 'twins': 1964,\n"," 'quadruplets': 1493,\n"," 'front': 726,\n"," 'skateboarding': 1681,\n"," 'accident': 49,\n"," 'break': 256,\n"," 'bike': 208,\n"," 'boston': 245,\n"," 'new': 1274,\n"," 'york': 2134,\n"," 'city': 376,\n"," 'see': 1622,\n"," 'how': 892,\n"," 'or': 1335,\n"," 'what': 2070,\n"," 'created': 449,\n"," 'civilization': 378,\n"," 'ends': 604,\n"," 'eat': 574,\n"," 'lay': 1047,\n"," 'potato': 1452,\n"," 'chips': 362,\n"," 'pringles': 1469,\n"," 'without': 2098,\n"," 'cell': 321,\n"," 'phone': 1409,\n"," 'ipod': 944,\n"," 'rock': 1565,\n"," 'star': 1769,\n"," 'infertile': 920,\n"," 'passes': 1376,\n"," 'away': 143,\n"," 'before': 188,\n"," 'age': 66,\n"," 'steal': 1780,\n"," 'an': 90,\n"," 'elderly': 585,\n"," 'woman': 2103,\n"," 'purse': 1491,\n"," 'tell': 1874,\n"," 'orphans': 1340,\n"," 'christmas': 368,\n"," 'is': 946,\n"," 'cancelled': 298,\n"," 'loved': 1117,\n"," 'lost': 1111,\n"," 'fruit': 728,\n"," 'vegetables': 2007,\n"," 'first': 685,\n"," 'killed': 1011,\n"," 'group': 793,\n"," 'last': 1040,\n"," 'spend': 1743,\n"," 'alone': 81,\n"," 'deep': 487,\n"," 'sea': 1614,\n"," 'submarine': 1807,\n"," 'space': 1734,\n"," 'station': 1777,\n"," 'make': 1132,\n"," 'out': 1343,\n"," 'cousin': 441,\n"," 'wear': 2054,\n"," 'cutoff': 467,\n"," 'shorts': 1651,\n"," 'taking': 1853,\n"," 'off': 1317,\n"," 'hair': 810,\n"," 'covering': 443,\n"," 'body': 233,\n"," 'completely': 414,\n"," 'bald': 154,\n"," '50': 22,\n"," 'burned': 275,\n"," '100': 2,\n"," 'tattooed': 1863,\n"," 'shotgun': 1653,\n"," 'beer': 184,\n"," 'funnel': 731,\n"," 'dumb': 558,\n"," 'punch': 1486,\n"," 'pilgrim': 1417,\n"," 'avocado': 141,\n"," 'black': 218,\n"," 'white': 2081,\n"," 'neighborhood': 1265,\n"," 'matt': 1159,\n"," 'damon': 471,\n"," 'ben': 197,\n"," 'affleck': 62,\n"," 'able': 40,\n"," 'lolspeak': 1104,\n"," 'type': 1967,\n"," '1337': 4,\n"," 'drive': 548,\n"," '200': 13,\n"," 'well': 2066,\n"," 'over': 1346,\n"," 'legal': 1057,\n"," 'drunken': 554,\n"," 'limit': 1081,\n"," 'after': 64,\n"," 'being': 192,\n"," 'awake': 142,\n"," '72': 29,\n"," 'straight': 1792,\n"," 'laugh': 1043,\n"," 'blonde': 225,\n"," 'jokes': 989,\n"," 'not': 1303,\n"," 'understand': 1977,\n"," 'sarcasm': 1599,\n"," 'die': 505,\n"," 'hypothermia': 900,\n"," 'hyperthermia': 899,\n"," 'heat': 839,\n"," 'contestant': 428,\n"," 'wheel': 2073,\n"," 'fortune': 711,\n"," 'jeopardy': 972,\n"," 'save': 1603,\n"," 'abraham': 43,\n"," 'lincoln': 1082,\n"," 'stop': 1788,\n"," 'showering': 1658,\n"," 'brushing': 265,\n"," 'average': 140,\n"," 'forgotten': 709,\n"," 'something': 1728,\n"," 'terrible': 1881,\n"," 'travel': 1939,\n"," 'world': 2115,\n"," 'confined': 420,\n"," 'wheelchair': 2074,\n"," 'same': 1591,\n"," 'radius': 1506,\n"," 'invincible': 940,\n"," 'invisible': 941,\n"," 'high': 852,\n"," 'salary': 1588,\n"," 'job': 980,\n"," 'hate': 827,\n"," 'low': 1119,\n"," 'love': 1116,\n"," 'truth': 1954,\n"," 'lie': 1072,\n"," 'fingernails': 678,\n"," 'toenails': 1920,\n"," 'removed': 1533,\n"," 'quickly': 1500,\n"," 'papercuts': 1367,\n"," 'webbing': 2056,\n"," 'between': 202,\n"," 'each': 567,\n"," 'finger': 677,\n"," 'toe': 1919,\n"," 'slowly': 1699,\n"," 'win': 2092,\n"," 'series': 1629,\n"," 'superbowl': 1818,\n"," 'read': 1516,\n"," 'write': 2124,\n"," 'sahara': 1586,\n"," 'desert': 493,\n"," 'north': 1301,\n"," 'pole': 1436,\n"," 'feet': 666,\n"," 'tall': 1855,\n"," 'caught': 317,\n"," 'home': 871,\n"," 'watching': 2049,\n"," 'sex': 1636,\n"," 'yourself': 2138,\n"," 'bar': 160,\n"," 'pink': 1420,\n"," 'martini': 1152,\n"," 'unable': 1971,\n"," 'experience': 632,\n"," 'sadness': 1585,\n"," 'anger': 94,\n"," 'heels': 842,\n"," 'dress': 544,\n"," 'stare': 1771,\n"," 'sun': 1814,\n"," 'minutes': 1200,\n"," 'drink': 546,\n"," 'liter': 1092,\n"," 'scalding': 1607,\n"," 'water': 2050,\n"," 'heaven': 840,\n"," 'hell': 844,\n"," 'reborn': 1521,\n"," 'into': 936,\n"," 'better': 201,\n"," 'worse': 2119,\n"," 'alcohol': 72,\n"," 'grain': 778,\n"," 'family': 651,\n"," 'samuel': 1592,\n"," 'vin': 2019,\n"," 'diesel': 507,\n"," 'violently': 2022,\n"," 'racist': 1505,\n"," 'intricate': 937,\n"," 'trek': 1945,\n"," 'giant': 753,\n"," 'birthmark': 214,\n"," '78': 31,\n"," 'face': 643,\n"," 'tail': 1850,\n"," 'sandlot': 1594,\n"," 'goonies': 772,\n"," 'taste': 1861,\n"," 'smell': 1705,\n"," 'get': 750,\n"," 'atomic': 132,\n"," 'wedgie': 2058,\n"," 'swirly': 1837,\n"," 'treehouse': 1944,\n"," 'floating': 693,\n"," 'boathouse': 231,\n"," 'paparazzi': 1365,\n"," 'follow': 698,\n"," 'around': 121,\n"," 'reveal': 1547,\n"," 'different': 509,\n"," 'secret': 1619,\n"," 'about': 42,\n"," 'weekly': 2061,\n"," 'newspaper': 1275,\n"," 'column': 400,\n"," 'genius': 746,\n"," 'unintelligent': 1983,\n"," 'people': 1395,\n"," 'geniuses': 747,\n"," 'fly': 697,\n"," 'breathe': 258,\n"," 'underwater': 1978,\n"," 'credited': 450,\n"," 'invention': 939,\n"," 'internet': 933,\n"," 'leave': 1052,\n"," 'native': 1260,\n"," 'overdressed': 1347,\n"," 'underdressed': 1976,\n"," 'oscar': 1341,\n"," 'nobel': 1291,\n"," 'prize': 1471,\n"," 'cinderella': 372,\n"," 'ariel': 116,\n"," 'whisper': 2080,\n"," 'shout': 1656,\n"," 'car': 305,\n"," 'kills': 1013,\n"," 'responsible': 1542,\n"," 'where': 2077,\n"," 'five': 687,\n"," 'closest': 384,\n"," 'friends': 723,\n"," 'lisp': 1089,\n"," 'lazy': 1048,\n"," 'eye': 638,\n"," 'extreme': 636,\n"," 'narcolepsy': 1255,\n"," 'bad': 151,\n"," 'case': 311,\n"," 'tourette': 1931,\n"," 'slytherin': 1700,\n"," 'gryffindor': 797,\n"," 'attractive': 137,\n"," 'punched': 1487,\n"," 'morning': 1224,\n"," 'ugly': 1969,\n"," 'head': 834,\n"," 'chef': 352,\n"," 'luxury': 1121,\n"," 'cruise': 455,\n"," 'liner': 1085,\n"," 'house': 890,\n"," 'ivy': 955,\n"," 'league': 1050,\n"," 'school': 1609,\n"," 'standard': 1768,\n"," 'university': 1986,\n"," '20': 12,\n"," '000': 0,\n"," 'worth': 2121,\n"," 'jewelry': 977,\n"," 'electronics': 589,\n"," 'nudist': 1309,\n"," 'colony': 398,\n"," 'amish': 87,\n"," 'ancient': 91,\n"," 'greece': 787,\n"," 'egypt': 583,\n"," 'pokemon': 1434,\n"," 'real': 1517,\n"," 'superheroes': 1820,\n"," 'exist': 631,\n"," 'skydive': 1688,\n"," 'bungie': 271,\n"," 'jump': 994,\n"," 'everywhere': 625,\n"," 'albino': 71,\n"," 'eyepatch': 640,\n"," 'peg': 1392,\n"," 'leg': 1056,\n"," 'nerd': 1266,\n"," 'jock': 981,\n"," 'excellent': 629,\n"," 'singer': 1671,\n"," 'superb': 1817,\n"," 'writer': 2125,\n"," 'skittles': 1687,\n"," 'monster': 1217,\n"," 'truck': 1952,\n"," 'chariot': 342,\n"," 'horses': 885,\n"," 'painted': 1358,\n"," 'van': 2002,\n"," 'gogh': 766,\n"," 'da': 469,\n"," 'vinci': 2020,\n"," 'elephant': 590,\n"," 'mouse': 1228,\n"," 'office': 1318,\n"," 'colonial': 397,\n"," 'normal': 1298,\n"," 'lifespan': 1074,\n"," 'modern': 1207,\n"," 'lightsaber': 1077,\n"," 'helper': 845,\n"," 'monkey': 1216,\n"," 'date': 476,\n"," 'topanga': 1927,\n"," 'boy': 251,\n"," 'meets': 1170,\n"," 'pam': 1361,\n"," 'large': 1038,\n"," 'painting': 1359,\n"," 'size': 1679,\n"," 'sculpture': 1613,\n"," 'rosa': 1574,\n"," 'parks': 1371,\n"," 'harriet': 823,\n"," 'tubman': 1957,\n"," '1st': 11,\n"," 'edition': 580,\n"," 'holographic': 870,\n"," 'charizard': 343,\n"," 'skip': 1686,\n"," 'summer': 1813,\n"," 'winter': 2096,\n"," 'gonzo': 770,\n"," 'cookie': 433,\n"," 'maker': 1133,\n"," 'bread': 255,\n"," 'winner': 2094,\n"," 'super': 1816,\n"," 'grover': 794,\n"," 'quail': 1494,\n"," 'lottery': 1113,\n"," 'twice': 1962,\n"," 'as': 125,\n"," 'long': 1105,\n"," 'jedi': 969,\n"," 'sith': 1676,\n"," 'cheating': 348,\n"," 'catch': 315,\n"," 'perform': 1401,\n"," 'petty': 1408,\n"," 'thievery': 1899,\n"," 'living': 1097,\n"," 'grand': 779,\n"," 'larceny': 1037,\n"," '1989': 10,\n"," 'dark': 474,\n"," 'knight': 1022,\n"," '2008': 14,\n"," 'rapper': 1512,\n"," 'notorious': 1306,\n"," 'mobster': 1206,\n"," 'attempt': 135,\n"," 'survive': 1827,\n"," 'computer': 416,\n"," 'uprising': 1993,\n"," 'terminator': 1880,\n"," 'zombie': 2143,\n"," 'outbreak': 1344,\n"," 'dawn': 478,\n"," 'dead': 482,\n"," 'ability': 39,\n"," 'teleport': 1872,\n"," 'past': 1378,\n"," 'future': 734,\n"," 'allergic': 77,\n"," 'peanut': 1386,\n"," 'butter': 284,\n"," 'chocolate': 363,\n"," 'sports': 1752,\n"," 'celebrated': 319,\n"," 'academic': 45,\n"," 'rich': 1552,\n"," 'vampire': 2001,\n"," 'werewolf': 2068,\n"," 'look': 1107,\n"," 'months': 1220,\n"," 'pregnant': 1462,\n"," 'knee': 1018,\n"," 'length': 1060,\n"," 'mohawk': 1208,\n"," 'emo': 598,\n"," 'gothic': 775,\n"," 'poor': 1447,\n"," 'feared': 661,\n"," 'uncontrollable': 1973,\n"," 'itch': 952,\n"," 'attacks': 134,\n"," 'sporradic': 1750,\n"," 'chapped': 338,\n"," 'lips': 1087,\n"," 'appear': 109,\n"," 'shivering': 1646,\n"," 'known': 1028,\n"," 'drug': 553,\n"," 'dealer': 484,\n"," 'liar': 1069,\n"," 'hawk': 833,\n"," 'shark': 1640,\n"," 'using': 1999,\n"," 'youtube': 2140,\n"," 'facebook': 644,\n"," 'civil': 377,\n"," 'war': 2040,\n"," 'revolutionary': 1550,\n"," 'magic': 1130,\n"," 'carpet': 307,\n"," 'ride': 1555,\n"," 'jasmine': 965,\n"," 'ball': 155,\n"," 'napoleon': 1254,\n"," 'julius': 993,\n"," 'caesar': 288,\n"," 'hang': 819,\n"," 'pooh': 1444,\n"," 'bear': 175,\n"," 'baloo': 157,\n"," 'jungle': 996,\n"," 'book': 242,\n"," 'course': 440,\n"," 'meal': 1165,\n"," 'starving': 1776,\n"," 'children': 357,\n"," 'bucket': 268,\n"," 'salvation': 1590,\n"," 'army': 120,\n"," 'santas': 1597,\n"," 'play': 1427,\n"," 'game': 736,\n"," 'jordan': 990,\n"," 'kobe': 1029,\n"," 'bryant': 267,\n"," 'questions': 1499,\n"," 'quotes': 1502,\n"," 'charleston': 344,\n"," 'macarena': 1125,\n"," 'called': 291,\n"," 'stupidity': 1805,\n"," 'admit': 57,\n"," 'listen': 1090,\n"," 'beatles': 179,\n"," 'rolling': 1569,\n"," 'stones': 1787,\n"," 'blood': 226,\n"," 'sucked': 1809,\n"," 'brain': 253,\n"," 'eaten': 575,\n"," 'person': 1404,\n"," 'walk': 2035,\n"," 'mars': 1151,\n"," 'via': 2015,\n"," 'way': 2051,\n"," 'trip': 1948,\n"," 'actually': 55,\n"," 'loud': 1114,\n"," 'lol': 1103,\n"," 'haha': 808,\n"," 'lmao': 1098,\n"," 'etc': 617,\n"," 'replicate': 1538,\n"," 'any': 105,\n"," 'emoticon': 599,\n"," 'use': 1998,\n"," 'elbow': 584,\n"," 'joints': 987,\n"," 'facing': 645,\n"," 'opposite': 1332,\n"," 'direction': 512,\n"," 'knees': 1020,\n"," 'backwards': 150,\n"," 'hunted': 898,\n"," 'jack': 956,\n"," 'bauer': 171,\n"," 'jason': 966,\n"," 'bourne': 249,\n"," 'when': 2075,\n"," 'are': 114,\n"," 'lying': 1122,\n"," 'horse': 883,\n"," 'jockey': 982,\n"," 'nascar': 1258,\n"," 'driver': 549,\n"," 'human': 895,\n"," 'remains': 1530,\n"," 'starve': 1775,\n"," 'quidditch': 1501,\n"," 'field': 668,\n"," 'ms': 1233,\n"," 'frizzle': 724,\n"," 'sexist': 1637,\n"," 'spouse': 1753,\n"," 'polygamist': 1440,\n"," 'relationship': 1528,\n"," 'longer': 1106,\n"," 'than': 1889,\n"," 'years': 2131,\n"," 'hindenburg': 854,\n"," 'titanic': 1915,\n"," 'british': 262,\n"," 'accent': 46,\n"," 'australian': 139,\n"," 'cinnamon': 373,\n"," 'challenge': 331,\n"," 'gallon': 735,\n"," 'gollum': 769,\n"," 'hook': 876,\n"," 'beetlejuice': 187,\n"," 'windows': 2093,\n"," 'macintosh': 1127,\n"," 'ebonics': 577,\n"," 'slang': 1690,\n"," 'whatsoever': 2072,\n"," 'romance': 1570,\n"," 'novels': 1307,\n"," 'textbooks': 1888,\n"," 'graphic': 782,\n"," 'designer': 494,\n"," 'architect': 113,\n"," 'taylor': 1864,\n"," 'swift': 1833,\n"," 'beyonce': 203,\n"," 'incredibly': 915,\n"," 'nice': 1278,\n"," 'own': 1351,\n"," 'personal': 1405,\n"," 'helicopter': 843,\n"," 'constantly': 424,\n"," 'stumble': 1802,\n"," 'walking': 2036,\n"," 'studder': 1798,\n"," 'speaking': 1739,\n"," 'heavy': 841,\n"," 'smoker': 1707,\n"," 'drinker': 547,\n"," 'magically': 1131,\n"," 'flip': 692,\n"," 'genders': 744,\n"," 'forced': 705,\n"," 'move': 1230,\n"," 'start': 1774,\n"," 'fresh': 720,\n"," 'seinfeld': 1623,\n"," 'simpsons': 1669,\n"," 'thing': 1900,\n"," 'clothes': 385,\n"," 'sick': 1663,\n"," 'kill': 1010,\n"," 'puppies': 1489,\n"," 'ray': 1514,\n"," 'vision': 2023,\n"," 'laser': 1039,\n"," 'bill': 210,\n"," 'fast': 656,\n"," 'food': 699,\n"," 'burgers': 273,\n"," 'night': 1283,\n"," 'chinese': 359,\n"," 'birthday': 213,\n"," 'innocent': 926,\n"," 'if': 903,\n"," 'would': 2122,\n"," 'end': 603,\n"," 'bloodshed': 227,\n"," 'middle': 1187,\n"," 'east': 573,\n"," '25': 16,\n"," 'ongoing': 1325,\n"," 'wars': 2044,\n"," 'terrorism': 1884,\n"," 'fighting': 670,\n"," 'extremely': 637,\n"," 'muscular': 1239,\n"," 'again': 65,\n"," 'console': 423,\n"," 'portable': 1449,\n"," 'device': 499,\n"," 'police': 1437,\n"," 'officer': 1319,\n"," 'firefighter': 683,\n"," 'professional': 1474,\n"," 'taser': 1860,\n"," 'testee': 1885,\n"," 'beanbag': 173,\n"," 'gun': 804,\n"," 'chug': 371,\n"," 'pint': 1422,\n"," 'ocean': 1313,\n"," 'salt': 1589,\n"," 'rancid': 1509,\n"," 'milk': 1193,\n"," 'goldeneye': 768,\n"," 'n64': 1248,\n"," 'halo': 811,\n"," 'xbox': 2127,\n"," 'myers': 1246,\n"," 'try': 1955,\n"," 'kruger': 1032,\n"," 'best': 199,\n"," 'male': 1134,\n"," 'friend': 722,\n"," 'sleeping': 1695,\n"," 'mom': 1211,\n"," 'sister': 1674,\n"," 'married': 1148,\n"," 'morbidly': 1222,\n"," 'obese': 1311,\n"," 'who': 2082,\n"," 'wealthy': 2053,\n"," 'georgous': 748,\n"," 'welfare': 2065,\n"," 'holes': 868,\n"," 'put': 1492,\n"," 'through': 1908,\n"," 'nails': 1250,\n"," 'hammer': 813,\n"," 'days': 480,\n"," 'universe': 1985,\n"," 'bagpipe': 152,\n"," 'music': 1240,\n"," 'banjo': 159,\n"," 'marry': 1149,\n"," 'ten': 1877,\n"," 'voice': 2027,\n"," 'peewee': 1391,\n"," 'herman': 847,\n"," 'perfectly': 1400,\n"," 'morgan': 1223,\n"," 'freeman': 716,\n"," 'terribly': 1882,\n"," 'crawl': 447,\n"," 'electric': 586,\n"," 'chair': 330,\n"," 'lethal': 1065,\n"," 'injection': 924,\n"," 'yell': 2132,\n"," 'swear': 1830,\n"," 'wrestle': 2123,\n"," 'alligator': 78,\n"," 'parent': 1369,\n"," 'weep': 2062,\n"," 'someone': 1727,\n"," 'tells': 1875,\n"," 'joke': 988,\n"," 'discover': 515,\n"," 'loch': 1101,\n"," 'ness': 1268,\n"," 'sasquatch': 1600,\n"," 'afraid': 63,\n"," 'goosebumps': 773,\n"," 'guts': 806,\n"," 'legends': 1058,\n"," 'hidden': 851,\n"," 'temple': 1876,\n"," 'buttons': 285,\n"," 'zippers': 2141,\n"," 'velcro': 2010,\n"," 'knots': 1025,\n"," 'late': 1041,\n"," 'unprepared': 1989,\n"," 'top': 1926,\n"," 'hat': 826,\n"," 'clock': 382,\n"," 'necklace': 1262,\n"," 'compliment': 415,\n"," 'complain': 412,\n"," 'three': 1906,\n"," 'strangers': 1794,\n"," 'nothing': 1305,\n"," 'ketchup': 999,\n"," 'week': 2060,\n"," 'mustard': 1243,\n"," 'meals': 1166,\n"," 'whatever': 2071,\n"," 'want': 2038,\n"," 'poop': 1446,\n"," 'sandwich': 1595,\n"," 'month': 1219,\n"," 'teach': 1866,\n"," 'math': 1158,\n"," 'story': 1791,\n"," 'roof': 1572,\n"," 'tackle': 1847,\n"," 'rugby': 1581,\n"," 'players': 1429,\n"," 'absolutely': 44,\n"," 'reek': 1523,\n"," 'armpits': 118,\n"," 'sense': 1625,\n"," 'saw': 1605,\n"," 'final': 674,\n"," 'destination': 496,\n"," 'stand': 1767,\n"," 'red': 1522,\n"," 'burning': 276,\n"," 'coals': 388,\n"," '30': 19,\n"," 'seconds': 1618,\n"," 'moving': 1232,\n"," 'shut': 1660,\n"," 'waffle': 2032,\n"," 'iron': 945,\n"," 'montague': 1218,\n"," 'capulet': 304,\n"," 'grown': 796,\n"," 'father': 658,\n"," 'mother': 1226,\n"," 'dr': 539,\n"," 'zoidberg': 2142,\n"," 'kif': 1009,\n"," 'cup': 460,\n"," 'baking': 153,\n"," 'soda': 1723,\n"," 'then': 1896,\n"," 'do': 523,\n"," 'vinegar': 2021,\n"," 'pack': 1353,\n"," 'mentos': 1177,\n"," 'diet': 508,\n"," 'met': 1183,\n"," 'jesus': 975,\n"," 'confucius': 421,\n"," 'starbucks': 1770,\n"," 'coffee': 391,\n"," 'dunkin': 560,\n"," 'donuts': 532,\n"," 'king': 1014,\n"," 'arthur': 123,\n"," 'knights': 1023,\n"," 'round': 1578,\n"," 'table': 1844,\n"," 'robin': 1563,\n"," 'hood': 875,\n"," 'merry': 1181,\n"," 'men': 1176,\n"," 'brutally': 266,\n"," 'assault': 129,\n"," 'member': 1172,\n"," 'ear': 569,\n"," 'nose': 1302,\n"," 'firefight': 682,\n"," 'odst': 1314,\n"," 'horde': 878,\n"," 'gears': 741,\n"," 'regular': 1525,\n"," 'daily': 470,\n"," 'soap': 1720,\n"," 'opera': 1330,\n"," 'line': 1083,\n"," 'cameos': 293,\n"," 'hollywood': 869,\n"," 'blockbusters': 224,\n"," 'commercial': 406,\n"," 'annoying': 97,\n"," 'geico': 742,\n"," 'ad': 56,\n"," 'verizon': 2013,\n"," 'can': 295,\n"," 'hear': 838,\n"," 'me': 1164,\n"," 'now': 1308,\n"," 'change': 335,\n"," 'religion': 1529,\n"," 'political': 1438,\n"," 'party': 1375,\n"," 'character': 340,\n"," 'heroes': 849,\n"," 'inventing': 938,\n"," 'whoopie': 2085,\n"," 'cushion': 465,\n"," 'snap': 1711,\n"," ...}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"jJA77J8xSYXD","executionInfo":{"status":"ok","timestamp":1645730130661,"user_tz":300,"elapsed":177,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"fdff07a5-6b00-427c-cbc4-52fe1e7e1c88"},"source":["i = 45000\n","j = 10\n","words = vectorizer.get_feature_names()[i:i+10]\n","pd.DataFrame(X_train[j:j+7, i:i+10].todense(), columns=words)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1b873055-0f99-4c0b-ab9e-1e6e7bfb548e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b873055-0f99-4c0b-ab9e-1e6e7bfb548e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1b873055-0f99-4c0b-ab9e-1e6e7bfb548e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1b873055-0f99-4c0b-ab9e-1e6e7bfb548e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: [0, 1, 2, 3, 4, 5, 6]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcMRWP0qSzbT","executionInfo":{"status":"ok","timestamp":1645730133699,"user_tz":300,"elapsed":152,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"da155576-f95f-4646-8838-fde3be2a1f68"},"source":["print(X_train)\n","print(X_train)\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (0, 1582)\t1\n","  (0, 18)\t1\n","  (0, 1190)\t1\n","  (1, 1190)\t1\n","  (1, 1834)\t1\n","  (2, 2137)\t1\n","  (2, 1374)\t1\n","  (2, 832)\t1\n","  (2, 874)\t1\n","  (2, 61)\t1\n","  (3, 2137)\t1\n","  (3, 1374)\t1\n","  (3, 832)\t1\n","  (3, 61)\t1\n","  (3, 850)\t1\n","  (4, 832)\t1\n","  (4, 1396)\t1\n","  (5, 832)\t1\n","  (5, 393)\t1\n","  (6, 2137)\t1\n","  (6, 2048)\t1\n","  (6, 1327)\t1\n","  (6, 543)\t1\n","  (6, 703)\t1\n","  (6, 1892)\t1\n","  :\t:\n","  (1369, 513)\t1\n","  (1369, 241)\t1\n","  (1370, 1327)\t1\n","  (1370, 1916)\t1\n","  (1370, 1094)\t1\n","  (1370, 172)\t1\n","  (1370, 40)\t1\n","  (1370, 1178)\t1\n","  (1370, 2133)\t1\n","  (1370, 1285)\t1\n","  (1370, 1096)\t1\n","  (1371, 1916)\t1\n","  (1371, 92)\t1\n","  (1371, 1323)\t1\n","  (1371, 1094)\t1\n","  (1371, 172)\t1\n","  (1371, 40)\t1\n","  (1371, 1854)\t1\n","  (1372, 2137)\t1\n","  (1372, 703)\t1\n","  (1372, 1322)\t1\n","  (1372, 818)\t1\n","  (1372, 1076)\t1\n","  (1372, 681)\t1\n","  (1372, 1199)\t1\n","  (0, 1582)\t1\n","  (0, 18)\t1\n","  (0, 1190)\t1\n","  (1, 1190)\t1\n","  (1, 1834)\t1\n","  (2, 2137)\t1\n","  (2, 1374)\t1\n","  (2, 832)\t1\n","  (2, 874)\t1\n","  (2, 61)\t1\n","  (3, 2137)\t1\n","  (3, 1374)\t1\n","  (3, 832)\t1\n","  (3, 61)\t1\n","  (3, 850)\t1\n","  (4, 832)\t1\n","  (4, 1396)\t1\n","  (5, 832)\t1\n","  (5, 393)\t1\n","  (6, 2137)\t1\n","  (6, 2048)\t1\n","  (6, 1327)\t1\n","  (6, 543)\t1\n","  (6, 703)\t1\n","  (6, 1892)\t1\n","  :\t:\n","  (1369, 513)\t1\n","  (1369, 241)\t1\n","  (1370, 1327)\t1\n","  (1370, 1916)\t1\n","  (1370, 1094)\t1\n","  (1370, 172)\t1\n","  (1370, 40)\t1\n","  (1370, 1178)\t1\n","  (1370, 2133)\t1\n","  (1370, 1285)\t1\n","  (1370, 1096)\t1\n","  (1371, 1916)\t1\n","  (1371, 92)\t1\n","  (1371, 1323)\t1\n","  (1371, 1094)\t1\n","  (1371, 172)\t1\n","  (1371, 40)\t1\n","  (1371, 1854)\t1\n","  (1372, 2137)\t1\n","  (1372, 703)\t1\n","  (1372, 1322)\t1\n","  (1372, 818)\t1\n","  (1372, 1076)\t1\n","  (1372, 681)\t1\n","  (1372, 1199)\t1\n","Training set score: 0.941\n","Test set score: 0.497\n"]}]},{"cell_type":"markdown","source":["##Statistical methods to check the seperation method/Prelim predictions"],"metadata":{"id":"p9Y2NwiW1Q6o"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"B4La9V2Tluue","executionInfo":{"status":"error","timestamp":1645741594393,"user_tz":300,"elapsed":161,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"fc00e253-898a-4d36-d8ab-afd539209a2f"},"source":["nb = MultinomialNB()\n","nb.fit(X_train, y_train)\n","print(\"Training set score: {:.3f}\".format(nb.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(nb.score(X_test, y_test)))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-4bea88af276c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training set score: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test set score: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \"\"\"\n\u001b[0;32m--> 663\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (779, 2) instead."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"8VfcMa4ymJGW","executionInfo":{"status":"error","timestamp":1645741589415,"user_tz":300,"elapsed":190,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"de043d9b-5fae-4e1f-9b30-34667a024d86"},"source":["review = \"Run around the whole city\"\n","\n","print(logreg.predict(vectorizer.transform([review]))[0])\n","print(nb.predict(vectorizer.transform([review]))[0])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-b88a21a5612c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Run around the whole city\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_dCI2JxmduI","executionInfo":{"status":"ok","timestamp":1645730188441,"user_tz":300,"elapsed":131,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"cca03fc0-1f25-48d5-d3a9-73de9243ac72"},"source":["review = \"Run 5 Miles\"\n","\n","print(logreg.predict(vectorizer.transform([review]))[0])\n","print(nb.predict(vectorizer.transform([review]))[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"sd5qzTbUmjw1","executionInfo":{"status":"error","timestamp":1645741556257,"user_tz":300,"elapsed":170,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"23de5e08-9b4e-4139-f757-4f62e3b5769c"},"source":["review = \"Eat an ice cream\"\n","\n","print(logreg.predict(vectorizer.transform([review]))[0])\n","print(nb.predict(vectorizer.transform([review]))[0])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-db0f04646983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Eat an ice cream\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"]}]},{"cell_type":"markdown","source":["The seperation method will prove to be ineffective at gathering conclusions based on the statistical methods above. Training data can become very seperatable with values in the 90s but fails at the testing stage. "],"metadata":{"id":"bcOU45Qtt4DV"}},{"cell_type":"markdown","source":["##LSTM on full questions"],"metadata":{"id":"_23q_i26uXPR"}},{"cell_type":"markdown","source":["Importing joint dataset"],"metadata":{"id":"g0emA3-kuvIS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IG9OJ6_hvrbd","executionInfo":{"status":"ok","timestamp":1645739973460,"user_tz":300,"elapsed":14555,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"ec17bfda-cc78-476c-8487-a81e119c08f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_directory = '/content/drive/MyDrive/CS/Datasets/wyr.csv'\n","db = pd.read_csv(data_directory)\n","\n","df = db[db.percent > 0]\n","print(df.shape)\n","\n","result = []\n","percentcol = df[\"percent\"]\n","\n","percent_list = percentcol.tolist()\n","\n","for i in percent_list:\n","  if i <=50:\n","    result.append(1)\n","  else:\n","    result.append(0)\n","print(result)\n","\n","df[\"result\"] = result\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"7yJYaspmuypC","executionInfo":{"status":"ok","timestamp":1645739975404,"user_tz":300,"elapsed":1950,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"16f09431-5303-421b-9251-58bf91901687"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(974, 3)\n","[1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f76ef11e-493e-4df9-a4dc-bff151d36d32\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>percent</th>\n","      <th>id</th>\n","      <th>result</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Run 26 miles or Swim 5 miles</td>\n","      <td>50</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Your partner have a homosexual affair or Your ...</td>\n","      <td>59</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Have a Pepsi or Have a Coke</td>\n","      <td>35</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Watch only dramas for the rest of your life or...</td>\n","      <td>14</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Burn to death or Drown</td>\n","      <td>31</td>\n","      <td>7</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f76ef11e-493e-4df9-a4dc-bff151d36d32')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f76ef11e-493e-4df9-a4dc-bff151d36d32 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f76ef11e-493e-4df9-a4dc-bff151d36d32');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                            question  percent  id  result\n","0                      Run 26 miles or Swim 5 miles        50   3       1\n","1  Your partner have a homosexual affair or Your ...       59   4       0\n","2                       Have a Pepsi or Have a Coke        35   5       1\n","3  Watch only dramas for the rest of your life or...       14   6       1\n","4                            Burn to death or Drown        31   7       1"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer(nb_words=2500, lower=True,split=' ')\n","tokenizer.fit_on_texts(df['question'].values)\n","\n","X = tokenizer.texts_to_sequences(df['question'].values)\n","X = pad_sequences(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzJUJhzau3PI","executionInfo":{"status":"ok","timestamp":1645740056091,"user_tz":300,"elapsed":156,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"a457cf14-e710-4a13-df52-aed286e20696"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n","  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.layers import LSTM, Dropout, Embedding, Dense\n","from keras.callbacks import EarlyStopping\n","from keras.constraints import maxnorm\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"ZkxvI4SeuuS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embed_dim = 128\n","lstm_out = 200\n","batch_size = 32\n","\n","model = Sequential()\n","model.add(Embedding(2500, embed_dim,input_length = X.shape[1]))\n","model.add(Dropout(.2))\n","model.add(LSTM(lstm_out))\n","model.add(Embedding(2500, embed_dim, input_length = lstm_out))\n","model.add(LSTM(lstm_out))\n","model.add(Dense(2,activation='sigmoid'))\n","model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9O-Mr1V9ubTX","executionInfo":{"status":"ok","timestamp":1645740713093,"user_tz":300,"elapsed":1802,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"01e98071-eb2c-4b6e-f617-9857b5278ba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_4 (Embedding)     (None, 44, 128)           320000    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 44, 128)           0         \n","                                                                 \n"," lstm_4 (LSTM)               (None, 200)               263200    \n","                                                                 \n"," embedding_5 (Embedding)     (None, 200, 128)          320000    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 200)               263200    \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 402       \n","                                                                 \n","=================================================================\n","Total params: 1,166,802\n","Trainable params: 1,166,802\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["y = pd.get_dummies(df['result']).values\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 36)\n","\n","model.fit(X_train, y_train, batch_size =batch_size, epochs = 20)\n","\n","model.evaluate(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPzsXirhufLp","executionInfo":{"status":"ok","timestamp":1645740701593,"user_tz":300,"elapsed":261098,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"5565afa1-528f-43e2-8aff-1673f6cb2429"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","WARNING:tensorflow:Gradients do not exist for variables ['embedding_2/embeddings:0', 'lstm_2/lstm_cell_2/kernel:0', 'lstm_2/lstm_cell_2/recurrent_kernel:0', 'lstm_2/lstm_cell_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['embedding_2/embeddings:0', 'lstm_2/lstm_cell_2/kernel:0', 'lstm_2/lstm_cell_2/recurrent_kernel:0', 'lstm_2/lstm_cell_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","25/25 [==============================] - 16s 495ms/step - loss: 0.6952 - accuracy: 0.4929\n","Epoch 2/20\n","25/25 [==============================] - 13s 516ms/step - loss: 0.6934 - accuracy: 0.4891\n","Epoch 3/20\n","25/25 [==============================] - 13s 499ms/step - loss: 0.6935 - accuracy: 0.4904\n","Epoch 4/20\n","25/25 [==============================] - 13s 501ms/step - loss: 0.6933 - accuracy: 0.4942\n","Epoch 5/20\n","25/25 [==============================] - 13s 500ms/step - loss: 0.6934 - accuracy: 0.4685\n","Epoch 6/20\n","25/25 [==============================] - 12s 498ms/step - loss: 0.6935 - accuracy: 0.4711\n","Epoch 7/20\n","25/25 [==============================] - 13s 501ms/step - loss: 0.6934 - accuracy: 0.4994\n","Epoch 8/20\n","25/25 [==============================] - 13s 499ms/step - loss: 0.6936 - accuracy: 0.4994\n","Epoch 9/20\n","25/25 [==============================] - 12s 498ms/step - loss: 0.6934 - accuracy: 0.4775\n","Epoch 10/20\n","25/25 [==============================] - 12s 496ms/step - loss: 0.6932 - accuracy: 0.4891\n","Epoch 11/20\n","25/25 [==============================] - 13s 540ms/step - loss: 0.6932 - accuracy: 0.4994\n","Epoch 12/20\n","25/25 [==============================] - 13s 500ms/step - loss: 0.6932 - accuracy: 0.4840\n","Epoch 13/20\n","25/25 [==============================] - 13s 499ms/step - loss: 0.6932 - accuracy: 0.4994\n","Epoch 14/20\n","25/25 [==============================] - 12s 497ms/step - loss: 0.6932 - accuracy: 0.4994\n","Epoch 15/20\n","25/25 [==============================] - 12s 493ms/step - loss: 0.6933 - accuracy: 0.4994\n","Epoch 16/20\n","25/25 [==============================] - 14s 550ms/step - loss: 0.6934 - accuracy: 0.4750\n","Epoch 17/20\n","25/25 [==============================] - 15s 601ms/step - loss: 0.6932 - accuracy: 0.4865\n","Epoch 18/20\n","25/25 [==============================] - 12s 498ms/step - loss: 0.6933 - accuracy: 0.4994\n","Epoch 19/20\n","25/25 [==============================] - 12s 496ms/step - loss: 0.6933 - accuracy: 0.4994\n","Epoch 20/20\n","25/25 [==============================] - 12s 496ms/step - loss: 0.6933 - accuracy: 0.4994\n","7/7 [==============================] - 2s 167ms/step - loss: 0.6931 - accuracy: 0.5179\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6931255459785461, 0.5179487466812134]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["print(X_train)\n","print(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en5LIB2hxZio","executionInfo":{"status":"ok","timestamp":1645740400730,"user_tz":300,"elapsed":156,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"2d418a30-51b3-4008-eeff-aae258e8fa67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[   0    0    0 ...  302   10  403]\n"," [   0    0    0 ...  115    7 1058]\n"," [   0    0    0 ... 1212  115   74]\n"," ...\n"," [   0    0    0 ...    4 1119  427]\n"," [   0    0    0 ...   20 2140 2141]\n"," [   0    0    0 ...    1    3 1027]]\n","[[0 1]\n"," [1 0]\n"," [1 0]\n"," ...\n"," [0 1]\n"," [1 0]\n"," [1 0]]\n"]}]},{"cell_type":"markdown","source":["##Multiheaded attention on full questions"],"metadata":{"id":"DUZ1O8KzuSKm"}},{"cell_type":"code","source":["class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)"],"metadata":{"id":"H6ZHiiN-wcLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"metadata":{"id":"ndEDwR_Zubvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 20000  # Only consider the top 20k words\n","maxlen = X_train.shape[1]  # Only consider the first 200 words of each\n","\n","print(len(X_train), \"Training sequences\")\n","print(len(X_test), \"Validation sequences\")\n","x_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n","x_val = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sd-knhiSwq0B","executionInfo":{"status":"ok","timestamp":1645740819929,"user_tz":300,"elapsed":182,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"03080301-d20d-48cb-be9f-5c0ee738413e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["779 Training sequences\n","195 Validation sequences\n"]}]},{"cell_type":"code","source":["embed_dim = 32  # Embedding size for each token\n","num_heads = 2  # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n","\n","inputs = layers.Input(shape=(maxlen,))\n","embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n","x = transformer_block(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","x = layers.Dropout(0.2)(x)\n","x = layers.Dense(20, activation=\"relu\")(x)\n","x = layers.Dropout(0.2)(x)\n","outputs = layers.Dense(2, activation=\"sigmoid\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"-4PzLSPywxa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","history = model.fit(\n","    X_train, y_train, batch_size=32, epochs=200, validation_data=(X_test, y_test)\n",")\n","\n","model.evaluate(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-6Z0mS-wzTw","executionInfo":{"status":"ok","timestamp":1645741324299,"user_tz":300,"elapsed":134424,"user":{"displayName":"Gunner Peterson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02754107879288077326"}},"outputId":"d3a82538-7283-467e-ad07-b0a5ef427ab6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","25/25 [==============================] - 3s 37ms/step - loss: 0.7142 - accuracy: 0.4929 - val_loss: 0.6962 - val_accuracy: 0.4821\n","Epoch 2/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.6981 - accuracy: 0.5135 - val_loss: 0.6928 - val_accuracy: 0.5231\n","Epoch 3/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.6879 - accuracy: 0.5584 - val_loss: 0.6947 - val_accuracy: 0.4821\n","Epoch 4/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.6836 - accuracy: 0.5571 - val_loss: 0.6934 - val_accuracy: 0.5179\n","Epoch 5/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.6698 - accuracy: 0.6226 - val_loss: 0.6968 - val_accuracy: 0.4923\n","Epoch 6/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.6628 - accuracy: 0.6033 - val_loss: 0.7086 - val_accuracy: 0.5179\n","Epoch 7/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.6178 - accuracy: 0.6958 - val_loss: 0.7049 - val_accuracy: 0.4974\n","Epoch 8/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.5044 - accuracy: 0.7985 - val_loss: 0.8432 - val_accuracy: 0.4974\n","Epoch 9/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.3661 - accuracy: 0.8652 - val_loss: 0.9627 - val_accuracy: 0.5282\n","Epoch 10/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.1975 - accuracy: 0.9448 - val_loss: 1.3010 - val_accuracy: 0.4769\n","Epoch 11/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.1170 - accuracy: 0.9666 - val_loss: 1.5484 - val_accuracy: 0.4872\n","Epoch 12/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0567 - accuracy: 0.9859 - val_loss: 1.9014 - val_accuracy: 0.4667\n","Epoch 13/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0497 - accuracy: 0.9859 - val_loss: 2.2609 - val_accuracy: 0.4872\n","Epoch 14/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 2.2116 - val_accuracy: 0.4923\n","Epoch 15/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0276 - accuracy: 0.9949 - val_loss: 2.3860 - val_accuracy: 0.4821\n","Epoch 16/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 2.4442 - val_accuracy: 0.5333\n","Epoch 17/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0231 - accuracy: 0.9961 - val_loss: 2.6358 - val_accuracy: 0.5282\n","Epoch 18/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 2.7087 - val_accuracy: 0.4821\n","Epoch 19/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 2.6809 - val_accuracy: 0.4974\n","Epoch 20/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 2.6995 - val_accuracy: 0.5128\n","Epoch 21/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 2.7454 - val_accuracy: 0.4821\n","Epoch 22/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 2.8156 - val_accuracy: 0.4974\n","Epoch 23/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 2.9212 - val_accuracy: 0.5128\n","Epoch 24/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 3.0770 - val_accuracy: 0.4974\n","Epoch 25/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 3.2122 - val_accuracy: 0.4872\n","Epoch 26/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 3.1771 - val_accuracy: 0.5077\n","Epoch 27/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0067 - accuracy: 0.9961 - val_loss: 3.1867 - val_accuracy: 0.5026\n","Epoch 28/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 3.2737 - val_accuracy: 0.4974\n","Epoch 29/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 3.2387 - val_accuracy: 0.5077\n","Epoch 30/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 3.3049 - val_accuracy: 0.5077\n","Epoch 31/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 3.3329 - val_accuracy: 0.4923\n","Epoch 32/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 3.3492 - val_accuracy: 0.4923\n","Epoch 33/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9974 - val_loss: 3.4016 - val_accuracy: 0.4974\n","Epoch 34/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 3.4413 - val_accuracy: 0.4974\n","Epoch 35/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0047 - accuracy: 0.9974 - val_loss: 3.4844 - val_accuracy: 0.5026\n","Epoch 36/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 3.5132 - val_accuracy: 0.5077\n","Epoch 37/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 3.4286 - val_accuracy: 0.5077\n","Epoch 38/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 3.4354 - val_accuracy: 0.5026\n","Epoch 39/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 3.4976 - val_accuracy: 0.4872\n","Epoch 40/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 3.5682 - val_accuracy: 0.5077\n","Epoch 41/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 3.6444 - val_accuracy: 0.4923\n","Epoch 42/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 3.5423 - val_accuracy: 0.4923\n","Epoch 43/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0037 - accuracy: 0.9974 - val_loss: 3.6250 - val_accuracy: 0.5077\n","Epoch 44/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 3.7326 - val_accuracy: 0.5077\n","Epoch 45/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 3.7710 - val_accuracy: 0.5128\n","Epoch 46/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 3.8475 - val_accuracy: 0.4923\n","Epoch 47/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 3.8027 - val_accuracy: 0.4923\n","Epoch 48/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 3.8756 - val_accuracy: 0.5077\n","Epoch 49/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 3.9733 - val_accuracy: 0.5128\n","Epoch 50/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 4.0565 - val_accuracy: 0.4974\n","Epoch 51/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 4.0872 - val_accuracy: 0.5179\n","Epoch 52/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9961 - val_loss: 4.0703 - val_accuracy: 0.5077\n","Epoch 53/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 4.0952 - val_accuracy: 0.4974\n","Epoch 54/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 4.1328 - val_accuracy: 0.5077\n","Epoch 55/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 4.1643 - val_accuracy: 0.5026\n","Epoch 56/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9961 - val_loss: 4.1710 - val_accuracy: 0.5128\n","Epoch 57/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 4.2456 - val_accuracy: 0.4974\n","Epoch 58/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 4.2229 - val_accuracy: 0.5077\n","Epoch 59/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.2925 - val_accuracy: 0.4923\n","Epoch 60/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 4.3462 - val_accuracy: 0.4974\n","Epoch 61/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 4.3761 - val_accuracy: 0.5077\n","Epoch 62/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 4.3874 - val_accuracy: 0.5077\n","Epoch 63/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.4199 - val_accuracy: 0.5077\n","Epoch 64/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 4.4529 - val_accuracy: 0.5077\n","Epoch 65/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 4.4899 - val_accuracy: 0.5077\n","Epoch 66/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 4.5432 - val_accuracy: 0.5179\n","Epoch 67/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 4.5502 - val_accuracy: 0.5026\n","Epoch 68/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 4.5809 - val_accuracy: 0.5077\n","Epoch 69/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 4.6207 - val_accuracy: 0.5128\n","Epoch 70/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 4.6355 - val_accuracy: 0.5077\n","Epoch 71/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 4.6550 - val_accuracy: 0.5026\n","Epoch 72/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 4.6746 - val_accuracy: 0.4974\n","Epoch 73/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 4.7211 - val_accuracy: 0.5077\n","Epoch 74/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 4.6261 - val_accuracy: 0.4974\n","Epoch 75/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.5959 - val_accuracy: 0.5077\n","Epoch 76/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.6419 - val_accuracy: 0.5231\n","Epoch 77/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9974 - val_loss: 4.6684 - val_accuracy: 0.5077\n","Epoch 78/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0038 - accuracy: 0.9974 - val_loss: 4.6997 - val_accuracy: 0.5128\n","Epoch 79/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0035 - accuracy: 0.9974 - val_loss: 4.7576 - val_accuracy: 0.5128\n","Epoch 80/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9974 - val_loss: 4.8891 - val_accuracy: 0.5077\n","Epoch 81/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 4.8682 - val_accuracy: 0.5128\n","Epoch 82/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 4.6638 - val_accuracy: 0.5077\n","Epoch 83/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 4.7073 - val_accuracy: 0.5026\n","Epoch 84/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.7624 - val_accuracy: 0.5026\n","Epoch 85/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 4.7986 - val_accuracy: 0.5026\n","Epoch 86/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 4.8569 - val_accuracy: 0.5128\n","Epoch 87/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 4.9133 - val_accuracy: 0.5128\n","Epoch 88/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 4.9404 - val_accuracy: 0.5128\n","Epoch 89/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 4.9901 - val_accuracy: 0.5128\n","Epoch 90/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 5.0191 - val_accuracy: 0.5128\n","Epoch 91/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 5.0768 - val_accuracy: 0.5077\n","Epoch 92/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.1436 - val_accuracy: 0.5026\n","Epoch 93/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 5.1845 - val_accuracy: 0.5026\n","Epoch 94/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 5.1358 - val_accuracy: 0.5128\n","Epoch 95/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 5.1470 - val_accuracy: 0.5128\n","Epoch 96/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 5.1509 - val_accuracy: 0.5026\n","Epoch 97/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 5.1749 - val_accuracy: 0.5026\n","Epoch 98/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9974 - val_loss: 5.2482 - val_accuracy: 0.5026\n","Epoch 99/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.3115 - val_accuracy: 0.5128\n","Epoch 100/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 5.3473 - val_accuracy: 0.5128\n","Epoch 101/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 5.3476 - val_accuracy: 0.5077\n","Epoch 102/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 5.3812 - val_accuracy: 0.5128\n","Epoch 103/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 5.4158 - val_accuracy: 0.5231\n","Epoch 104/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 5.4400 - val_accuracy: 0.5128\n","Epoch 105/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 4.6442 - val_accuracy: 0.5077\n","Epoch 106/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 4.6939 - val_accuracy: 0.5128\n","Epoch 107/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 4.8930 - val_accuracy: 0.5179\n","Epoch 108/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 5.0912 - val_accuracy: 0.5128\n","Epoch 109/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 5.1359 - val_accuracy: 0.5179\n","Epoch 110/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 5.2442 - val_accuracy: 0.5077\n","Epoch 111/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 5.2954 - val_accuracy: 0.5179\n","Epoch 112/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 5.3354 - val_accuracy: 0.5179\n","Epoch 113/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 5.3848 - val_accuracy: 0.5077\n","Epoch 114/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 5.4407 - val_accuracy: 0.5128\n","Epoch 115/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 5.4658 - val_accuracy: 0.5128\n","Epoch 116/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 5.5192 - val_accuracy: 0.5128\n","Epoch 117/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 5.5532 - val_accuracy: 0.5128\n","Epoch 118/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 5.5883 - val_accuracy: 0.5128\n","Epoch 119/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 5.6037 - val_accuracy: 0.5128\n","Epoch 120/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 5.6296 - val_accuracy: 0.5128\n","Epoch 121/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 5.6634 - val_accuracy: 0.5128\n","Epoch 122/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 5.7304 - val_accuracy: 0.5179\n","Epoch 123/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 5.7548 - val_accuracy: 0.5179\n","Epoch 124/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 5.7148 - val_accuracy: 0.5128\n","Epoch 125/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 5.7604 - val_accuracy: 0.5128\n","Epoch 126/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 5.7511 - val_accuracy: 0.5128\n","Epoch 127/200\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 5.8016 - val_accuracy: 0.5128\n","Epoch 128/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 5.8477 - val_accuracy: 0.5179\n","Epoch 129/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 5.9219 - val_accuracy: 0.5077\n","Epoch 130/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 5.9363 - val_accuracy: 0.5128\n","Epoch 131/200\n","25/25 [==============================] - 1s 31ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.0258 - val_accuracy: 0.5077\n","Epoch 132/200\n","25/25 [==============================] - 1s 50ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 6.0736 - val_accuracy: 0.5128\n","Epoch 133/200\n","25/25 [==============================] - 1s 40ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 5.9567 - val_accuracy: 0.5128\n","Epoch 134/200\n","25/25 [==============================] - 1s 44ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 5.9951 - val_accuracy: 0.5128\n","Epoch 135/200\n","25/25 [==============================] - 1s 43ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.0504 - val_accuracy: 0.5179\n","Epoch 136/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 6.0633 - val_accuracy: 0.5179\n","Epoch 137/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.0515 - val_accuracy: 0.5128\n","Epoch 138/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.0962 - val_accuracy: 0.5179\n","Epoch 139/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.1284 - val_accuracy: 0.5128\n","Epoch 140/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.1554 - val_accuracy: 0.5128\n","Epoch 141/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 6.1734 - val_accuracy: 0.5179\n","Epoch 142/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.2481 - val_accuracy: 0.5179\n","Epoch 143/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9974 - val_loss: 6.2205 - val_accuracy: 0.5128\n","Epoch 144/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 6.1858 - val_accuracy: 0.5077\n","Epoch 145/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 6.2545 - val_accuracy: 0.5026\n","Epoch 146/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.2720 - val_accuracy: 0.5026\n","Epoch 147/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 6.2944 - val_accuracy: 0.5077\n","Epoch 148/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 6.3331 - val_accuracy: 0.5077\n","Epoch 149/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 6.3549 - val_accuracy: 0.5077\n","Epoch 150/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.4156 - val_accuracy: 0.5179\n","Epoch 151/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.4494 - val_accuracy: 0.5179\n","Epoch 152/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 6.3938 - val_accuracy: 0.5077\n","Epoch 153/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.4193 - val_accuracy: 0.5026\n","Epoch 154/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.4151 - val_accuracy: 0.5077\n","Epoch 155/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 6.4107 - val_accuracy: 0.5077\n","Epoch 156/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 6.4324 - val_accuracy: 0.5077\n","Epoch 157/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.4629 - val_accuracy: 0.5026\n","Epoch 158/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.4873 - val_accuracy: 0.5026\n","Epoch 159/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.5021 - val_accuracy: 0.5077\n","Epoch 160/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 6.5089 - val_accuracy: 0.5077\n","Epoch 161/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 6.5277 - val_accuracy: 0.5077\n","Epoch 162/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 6.5504 - val_accuracy: 0.5179\n","Epoch 163/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.5619 - val_accuracy: 0.5179\n","Epoch 164/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 6.5727 - val_accuracy: 0.5026\n","Epoch 165/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.5997 - val_accuracy: 0.5128\n","Epoch 166/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.6475 - val_accuracy: 0.5179\n","Epoch 167/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 6.7025 - val_accuracy: 0.5179\n","Epoch 168/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 6.7291 - val_accuracy: 0.5077\n","Epoch 169/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 6.7569 - val_accuracy: 0.5077\n","Epoch 170/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.7685 - val_accuracy: 0.5026\n","Epoch 171/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.7748 - val_accuracy: 0.5026\n","Epoch 172/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.7833 - val_accuracy: 0.5026\n","Epoch 173/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 6.7874 - val_accuracy: 0.5077\n","Epoch 174/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9974 - val_loss: 6.7693 - val_accuracy: 0.5128\n","Epoch 175/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.8304 - val_accuracy: 0.5231\n","Epoch 176/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 6.8600 - val_accuracy: 0.5128\n","Epoch 177/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9961 - val_loss: 7.0071 - val_accuracy: 0.5128\n","Epoch 178/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 7.0855 - val_accuracy: 0.5231\n","Epoch 179/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 7.2070 - val_accuracy: 0.5179\n","Epoch 180/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9974 - val_loss: 6.0064 - val_accuracy: 0.5026\n","Epoch 181/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9974 - val_loss: 5.8984 - val_accuracy: 0.5282\n","Epoch 182/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 6.1159 - val_accuracy: 0.5282\n","Epoch 183/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.1797 - val_accuracy: 0.5128\n","Epoch 184/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.2912 - val_accuracy: 0.5128\n","Epoch 185/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.3959 - val_accuracy: 0.5128\n","Epoch 186/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 6.3413 - val_accuracy: 0.5128\n","Epoch 187/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 6.3672 - val_accuracy: 0.5179\n","Epoch 188/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.4431 - val_accuracy: 0.5179\n","Epoch 189/200\n","25/25 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 6.5342 - val_accuracy: 0.5231\n","Epoch 190/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 6.5522 - val_accuracy: 0.5179\n","Epoch 191/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 6.5960 - val_accuracy: 0.5179\n","Epoch 192/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 6.6209 - val_accuracy: 0.5179\n","Epoch 193/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.6227 - val_accuracy: 0.5179\n","Epoch 194/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 6.6341 - val_accuracy: 0.5179\n","Epoch 195/200\n","25/25 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 6.7477 - val_accuracy: 0.5179\n","Epoch 196/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 6.7418 - val_accuracy: 0.5179\n","Epoch 197/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 6.7510 - val_accuracy: 0.5179\n","Epoch 198/200\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 6.7845 - val_accuracy: 0.5179\n","Epoch 199/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 6.8002 - val_accuracy: 0.5128\n","Epoch 200/200\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 6.7380 - val_accuracy: 0.5128\n","7/7 [==============================] - 0s 6ms/step - loss: 6.7380 - accuracy: 0.5128\n"]},{"output_type":"execute_result","data":{"text/plain":["[6.737952709197998, 0.5128205418586731]"]},"metadata":{},"execution_count":32}]}]}